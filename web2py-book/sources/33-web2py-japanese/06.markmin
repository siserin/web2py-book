## データベース抽象化レイヤ
``DAL``:inxx

### 依存関係

web2pyは、データベース抽象化層(DAL)を備えています。これは、Pythonオブジェクトを、クエリやテーブル、レコードなどのデーターベース・オブジェクトに対応付けするAPIです。DALは、データベース・バックエンド固有の方言を用いてSQLをリアルタイムで動的に生成します。そのため、開発者はSQLコードを書く必要がなく、また、異なるSQL方言を学ぶ必要もありません(SQLという言葉は総称的に用いています)。そして、アプリケーションは異なるタイプのデータベース間でポータブルになります。この文書の執筆時点で、サポートされているデータベースは、SQLite(Pythonに備わっています。したがってweb2pyにも備わっています)、PostgreSQL、MySQL、Oracle、MSSQL、FireBird、DB2、Informix、Ingres、(部分的に)the GoogleApp Engine(SQL及びNoSQL)です。実験的に他の多くのデータベースもサポートしています。web2pyのウェブサイトやメーリングリストで最新の適応状況を確認してください。Google NoSQLは、第13章で具体的な事例として扱います。

Windowsのバイナリ・ディストリビューションは、SQLiteとMySQLと一緒にすぐ使えます。Macのバイナリ・ディストリビューションは、SQLiteと一緒にすぐに使えます。他のデータベースバックエンドを使うには、ソース・ディストリビューションから実行し、バックエンドに必要な適切なドライバをインストールしてください。``database drivers``:inxx

適切なドライバをインストールしたら、web2pyをソースから起動してください。web2pyはドライバを見つけます。以下はドライバのリストです：

----------
database | driver (source)
SQLite | sqlite3 or pysqlite2 or zxJDBC ``zxjdbc``:cite  (on Jython)
PostgreSQL | psycopg2 ``psycopg2``:cite  or zxJDBC ``zxjdbc``:cite  (on Jython)
MySQL | pymysql ``pymysql``:cite or MySQLdb ``mysqldb``:cite
Oracle | cx_Oracle ``cxoracle``:cite
MSSQL | pyodbc ``pyodbc``:cite
FireBird | kinterbasdb ``kinterbasdb``:cite
DB2 | pyodbc ``pyodbc``:cite
Informix | informixdb ``informixdb``:cite
Ingres | ingresdbi ``ingresdbi``:cite
---------

(``pymysql`` ships with web2py)

web2pyは、DALを構成する次のクラスを定義しています：

**DAL**は、データベース接続を表します。例:
``sqlite``:inxx
``
db = DAL('sqlite://storage.db')
``:code

``define_table``:inxx
**Table**はデータベースのテーブルを表します。Tableを直接インスタンス化するのではなく、代わりに、``DAL.define_table``によってインスタンス化します。
``
db.define_table('mytable', Field('myfield'))
``:code

Tableの中で最も重要なメソッドは以下のものです：
``insert``:inxx
``truncate``:inxx
``drop``:inxx
``import_from_csv_file``:inxx
``count``:inxx
``.insert``, ``.truncate``, ``.drop``, and ``.import_from_csv_file``.

``Field``:inxx
**Field**はデータベースのフィールドを表します。インスタンス化し、``DAL.define_table``へ引数として渡すことができます。

``Rows``:inxx
**DAL Rows** ``Row``:inxxはデータベースの選択によって返されるオブジェクトです。``Row``の行からなるリストとして考えることができます：
``
rows = db(db.mytable.myfield!=None).select()
``:code

``Row``:inxx
**Row**はフィールドの値を保持します。
``
for row in rows:
    print row.myfield
``:code

``Query``:inxx
**Query**はSQLの"where"句を表現するオブジェクトです：
``
myquery = (db.mytable.myfield != None) | (db.mytable.myfield > 'A')
``:code

``Set``:inxx
**Set**はレコードのセットを表します。最も重要なメソッドは、``count``、``select``、``update``、``delete``です。例:
``
myset = db(myquery)
rows = myset.select()
myset.update(myfield='somevalue')
myset.delete()
``:code

``Expression``:inxx
**Expression**は``orderby``や``groupby``式のようなものです。Fieldクラスは、Expressionから派生しています。下に例を示します。
``
myorder = db.mytable.myfield.upper() | db.mytable.id
db().select(db.table.ALL, orderby=myorder)
``:code

### 接続文字列
``connection strings``:inxx

データベースとの接続は、DALのオブジェクトのインスタンスを作成することによって確立されます：
``
>>> db = DAL('sqlite://storage.db', pool_size=0)
``:code
``db``はキーワードではありません。それはローカルな変数で、接続オブジェクト``DAL``を格納します。違う名前を付けても問題ありません。``DAL``のコンストラクタは1つの引数、すなわち接続文字列を必要とします。接続文字列は、特定のバックエンドのデータベースに依存する唯一のweb2pyコードです。ここでは、サポートされているバックエンドのデータベースの具体的な接続文字列の例を示します(全てのケースで、データベースは、localhostのデフォルトポート上で動作し、"test"という名前だと仮定しています)：

-------------
**SQLite**     | ``sqlite://storage.db``
**MySQL**      | ``mysql://username:password@localhost/test``
**PostgreSQL** | ``postgres://username:password@localhost/test``
**MSSQL**      | ``mssql://username:password@localhost/test``
**FireBird**   | ``firebird://username:password@localhost/test``
**Oracle**     | ``oracle://username/password@test``
**DB2**        | ``db2://username:password@test``
**Ingres**     | ``ingres://username:password@localhost/test``
**Informix**   | ``informix://username:password@test``
**Google App Engine/SQL** | ``google:sql``
**Google App Engine/NoSQL** | ``google:datastore``
-------------

SQLiteではデータベースが、単一のファイルからなることに注意してください。ファイルが存在しない場合は作成されます。このファイルはアクセスするたびにロックされます。MySQL、PostgreSQL、MSSQL。FireBird、Oracle、DB2、Ingres、Informixの場合、"test"データベースはweb2pyの外部で作成される必要があります。接続が確立されると、web2pyは、テーブルを適切に作成、変更、削除します。

接続文字列を``None``に設定することも可能です。この場合、DALはいかなるバックエンド・データベースにも接続しませんが、テスト用途としてAPIにはアクセス可能です。この例は、第7章で説明します。

#### 接続プール
``connection pooling``:inxx

DALのコンストラクタの2番目の引数は``pool_size``です。デフォルトでは0になります。

各リクエストに対して新規のデータベース接続を確立するのはそれなりに遅いので、web2pyは接続プール機構を実装しています。接続が確立し、ページが処理され、トランザクションが完了すると、その接続は閉じず、プールにされます。次のHTTPリクエストが来ると、web2pyはそのプールから接続を取得して、新規のトランザクションに利用しようと試みます。もしプールに利用可能な接続が存在しないと、新しい接続を確立します。

``pool_size``パラメタは、SQLiteとGAEでは無視されます。

プール内の接続は、スレッド間で順番に共有されます。つまり、それらは2つの異なるスレッドによって利用されますが、同時には利用されません。また、それぞれのweb2pyのプロセスには、1つのプールしかありません。

web2pyの起動時は、プールは常に空です。プールは、``pool_size``の値か最大同時リクエスト数の、どちらか少ない方まで増えます。つまり、``pool_size=10``でも、サーバーが5より多いリクエスト数を受け付けない場合、実際のプールサイズは5までしか成長しません。``pool_size=0``の場合は、接続プールは使用されません。

接続プールはSQLiteの場合は無視されます。特に恩恵がないからです。

#### 接続の失敗

web2pyがデータベースへの接続に失敗した場合、1秒間待機し、さらに接続の試みを5回、失敗の確定までに行います。接続プールではプールされている接続の中で、オープンになっているが暫く使用していないものを、データベース側でクローズにすることが可能です。再試行の機能によりweb2pyは、切断した接続に対する再確立を試みます。

接続プールを使って接続を行うと、プールに戻されリサイクルされます。プール中の使用されていない接続は、データベースサーバーによってクローズされることもあります。これは、障害やタイムアウトによって発生します。web2pyはその発生を検知し、接続を再確立します。

#### 複製されたデータベース

``DAL(...)``の最初の引数には、URIのリストをとることもできます。この場合、web2pyはそれぞれに接続しようと試みます。その主な目的は、複数のデータベースサーバーに対応し、それらの間で負荷を分散させることです。ここでは典型的なユースケースを示します：

``
db = DAL(['mysql://...1','mysql://...2','mysql://...3'])
``:code

この場合、DALは最初のものに接続しようと試み、失敗したら、第2、第3のものに試みます。これは、マスタ-スレーブ構成のデータベースにおいて負荷を分散するためにも利用できます。詳細は、第13章のスケーラビリティの中で説明します。

### 予約キーワード
``reserved Keywords``:inxx

DALのコンストラクタに渡すことのできる、もう1つの引数があります。これは、対象となるバックエンドのデータベースにおける予約されたSQLのキーワードに対してテーブルの名前や、カラムの名前をチェックすることができます。

その引数は、``check_reserved``です。デフォルトはNoneです。

これは、データベース・バックエンドのアダプタの名前を含む文字列のリストです。

アダプタの名前は、DALの接続文字列において使用されているものと同じです。例えば、PostgreSQLとMSSQLに対してチェックしたい場合は、次のような接続文字列になります：
``
db = DAL('sqlite://storage.db',
         check_reserved=['postgres', 'mssql'])
``:code

DALはリストと同じ順番で、キーワードを走査します。

"all"と"common"という2つの追加オプションがあります。allを指定すると、全ての知られているSQLキーワードに対してチェックされます。commonを指定すると、``SELECT``、``INSERT``、``UPDATE``などの一般的なSQLのキーワードだけがチェックされます。

サポートされるバックエンドに対して、非予約語のSQLキーワードをチェックするかどうかを指定することも可能です。この場合、``_nonreserved``をその名前に追加してください。例:
``
check_reserved=['postgres', 'postgres_nonreserved']
``:code

以下のデータベース・バックエンドは、予約語のチェックをサポートしています。

-----
**PostgreSQL** | ``postgres(_nonreserved)``
**MySQL** | ``mysql``
**FireBird** | ``firebird(_nonreserved)``
**MSSQL** | ``mssql``
**Oracle** | ``oracle``
-----

### ``DAL``, ``Table``, ``Field``

DALのAPIを理解する最良の方法は、それぞれの関数を自分で試してみることです。これは、web2pyのシェルを介してインタラクティブで実行することができます。とはいえ最終的に、DALコードはモデルとコントローラに設置します。

接続を作成して始めましょう。例なので、SQLiteを使用してもよいでしょう。バックエンドのエンジンを変更したとしても、この記事では他に何も変更するものはありません。

``DAL``:inxx ``SQLite``:inxx ``MySQL``:inxx ``PostgresSQL``:inxx ``Oracle``:inxx ``MSSQL``:inxx ``FireBird``:inxx ``DB2``:inxx ``Informix``:inxx
``
>>> db = DAL('sqlite://storage.db')
``:code

データベースは今接続されて、その接続はグローバル変数``db``に格納されます。

いつでも、接続文字列を取り出すことができます。
``_uri``:inxx
``
>>> print db._uri
sqlite://storage.db
``:code

データベース名も取り出せます。
``_dbname``:inxx
``
>>> print db._dbname
sqlite
``:code

接続文字列は``_uri``と呼ばれます。これは、Uniform Resource Identifierのインスタンスだからです。

DALでは、同じデータベースや異なるデータベース、さらに、異なる種類のデータベースに対する複数の接続が可能です。ここでは、最も一般的な状況として、単一のデータベースを想定します。

``define_table``:inxx ``Field``:inxx
``type``:inxx ``length``:inxx ``default``:inxx ``requires``:inxx ``required``:inxx ``unique``:inxx
``notnull``:inxx ``ondelete``:inxx ``uploadfield``:inxx ``uploadseparate``:inxx ``migrate``:inxx ``sql.log``:inxx

DALの最も重要なメソッドは``define_table``です：
``
>>> db.define_table('person', Field('name'))
``:code

これは、"name"フィールド(カラム)を持つ"person"という``Table``オブジェクトを定義し、格納し、返しています。このオブジェクトはまた、``db.person``に関連付けられているので、その戻り値を捉える必要はありません。

web2pyが何れにせよ作成するため、"id"というフィールドは宣言しないでください。全てのテーブルは、"id"というフィールドをデフォルトで持っています。これは、(1から始まる)自動インクリメントした整数のフィールドで、相互参照や、各レコードをユニークにするために用いられます。すなわち、"id"はプライマリーキーです。(注：idが1から始まるかはバックエンドによります。例えばこれは、Google App Engine NoSQLでは適用されません。)

``named id field``:inxx
オプション的に、type='id'とするフィールドを定義することができます。web2pyはこのフィールドを自動インクリメントしたidフィールドとして使用します。これは、レガシーなデータベーステーブルにアクセスする時以外には推奨されません。いくつかの制約がありますが、複数の異なるプライマリキーを使用することもできます。これについては、"レガシー・データベースとキー付きテーブル"のセクションで後述します。


### レコードの表現

これはオプションですが、レコードの書式表現を指定するのを推奨されています：
``
>>> db.define_table('person', Field('name'), format='%(name)s')
``:code

または
``
>>> db.define_table('person', Field('name'), format='%(name)s %(id)s')
``:code

より複雑なものは関数を用いて次のように書きます：
``
>>> db.define_table('person', Field('name'),
       format=lambda r: r.name or 'anonymous')
``:code

format属性は、2つの目的のために使用されます：
- セレクト/オプションのドロップダウンにおいて、参照先のレコードを表現するため。
- このテーブルを参照する全てのフィールドに対して、``db.othertable.person.represent``属性を設定するためです。これは、SQLTABLEがidによって参照を表示するのではなく、代わりに好ましい書式表現を用いることを意味します。


``Field constructor``:inxx
以下に示すのはFieldコンストラクタのデフォルトの値です：
``
Field(name, 'string', length=None, default=None,
      required=False, requires='<default>',
      ondelete='CASCADE', notnull=False, unique=False,
      uploadfield=True, widget=None, label=None, comment=None,
      writable=True, readable=True, update=None, authorize=None,
      autodelete=False, represent=None, compute=None,
      uploadfolder=os.path.join(request.folder,'uploads'),
      uploadseparate=None)
``:code

全てのものが各フィールドに関連しているというわけではありません。"length"は、"string"型のフィールドに対してのみ関連しています。"uploadfield"と"authorize"は、"upload"型のフィールドに対してのみ関連しています。"ondelete" は"reference"と"upload"型のフィールドに対してにみ関連しています。
- ``length``は"string"や、"password"、"upload"フィールドの最大長を設定します。``length``が指定されていない場合は、デフォルト値が使用されます。ただし、デフォルト値に関しては後方互換は保証されていません。意図しないマイグレーションやアップグレードを避けるため、string、password、uploadフィールドに対して、常にlengthを指定することを推奨します。
- ``default``はフィールドのデフォルト値を設定します。デフォルト値は値が明示的に指定されていない場合において、挿入を実行したときに使用されます。また、SQLFORMを用いてテーブルから構築されたフォームで、事前入力のために使用されます。注意点として、固定値を指定する代わりに、適切な値を返す関数（lambdaを含む）を使用することができます。この場合、複数のレコードが一つのトランザクションで挿入されても、各レコードが挿入されるたびに関数が呼び出されます。
- ``required``はDALに、このフィールドの値が明示的に指定されていない場合、挿入することを許さないようにします。
- ``requires``はバリデータ、または、バリデータのリストです。これは、DALによっては使用されず、SQLFORMによって使用されます。以下に、与えられた型に対するデフォルトのバリデータの一覧を示します：

----------
**field type** | **default field validators**
``string`` | ``IS_LENGTH(length)`` default length is 512
``text`` | ``IS_LENGTH(65536)``
``blob`` | ``None``
``boolean`` | ``None``
``integer`` | ``IS_INT_IN_RANGE(-1e100, 1e100)``
``double`` | ``IS_FLOAT_IN_RANGE(-1e100, 1e100)``
``decimal(n,m)`` | ``IS_DECIMAL_IN_RANGE(-1e100, 1e100)``
``date`` | ``IS_DATE()``
``time`` | ``IS_TIME()``
``datetime`` | ``IS_DATETIME()``
``password`` | ``None``
``upload`` | ``None``
``reference <table>``  | ``IS_IN_DB(db,table.field,format)``
``list:string`` | ``None``
``list:integer`` | ``None``
``list:reference <table>`` | ``IS_IN_DB(db,table.field,format,multiple=True)``
---------

Decimalは、Pythonの``decimal``モジュールに定義されているような、``Decimal``オブジェクトを要求し返します。SQLiteでは``decimal``型は処理されないので、``double``として扱われます。(n、m)はそれぞれ、合計の桁数と小数点以下の桁数です。

``list:`` フィールドは特殊です。なぜなら、NoSQL上の特定の非正規化の特徴(Google App Engine NoSQL では、``ListProperty``や``StringListProperty``といったフィールド型)に対して有利になるように、そして、それらを他のサポートされたリレーショナル・データベースに移植できるように設計されているからです。リレーショナルデータベースでは、リストは``text``フィールドとして格納されます。項目は、``|``によって区切られ、文字列項目の各``|``は``||``にエスケープされます。詳細は、listフィールドのセクションで説明します。

-------
``requires=...``は、フォーム・レベルで強制され、``required=True``はDAL(挿入)レベルで強制されることに注意してください。一方、``notnull``や``unique``、``ondelete``はデータベース・レベルで強制されます。それらは時として冗長に見えるかもしれませんが、DALを用いたプログラミングにおいて、その区別を管理することは重要です。
-------

``ondelete``:inxx

- ``ondelete`` は"ON DELETE"SQL文へと変換されます。デフォルトでは、"CASCADE"に設定されています。これは、レコードを削除する時に、それを参照している全てのレコードを削除するようにデータベースに指示します。この機能を無効にするには、ondeleteを"NO ACTION"、または"SET NULL"に設定してください。
- ``notnull=True`` は"NOT NULL"SQL文へと変換されます。これにより、データベースから、このフィールドにnull値が挿入されることを防ぎます。
- ``unique=True`` は"UNIQUE"SQL文へと変換され、フィールドの値が、そのテーブル内でユニークであることを保証します。これはデータベース・レベルで強制されます。

- ``uploadfield``は "upload"型のフィールドに対してのみ適用されます。"upload"型のフィールドはどこか他に保存されたファイル、デフォルトではアプリケーションの"uploads/"フォルダ以下のファイルシステム上に保存されたファイルの名前を格納します。``uploadfield``が設定されている場合、ファイルは同じテーブルのblobフィールドに格納され、``uploadfield``の値はそのblobフィールドの名前になります。この点に関してはSQLFORMのコンテキストでより詳しく後述します。
- ``uploadfolder`` はデフォルトではアプリケーションの"uploads/"フォルダになります。別のパスが設定されている場合、ファイルは別のフォルダにアップロードされます。例えば、``uploadfolder=os.path.join(request.folder,'static/temp')``とすると、ファイルは``web2py/applications/myapp/static/temp``フォルダにアップロードされます。
- ``uploadseparate`` は、Trueに設定されていると、ファイルはuploadfolderフォルダの異なるサブフォルダの下にアップロードされます。これは、非常に多くのファイルを同じフォルダ/サブフォルダに置くことを回避するために最適化されています。注意：システムの中断なしに、uploadseparateの値をTrueからFalseに変更することはできません。web2pyは分解したサブフォルダを使用するかしないかのどちらかしかとることはできません。ファイルをアップロードしてからこの挙動を変更すると、web2pyはそれらのファイルを取り出すことができなくなります。これが起こった場合は、ファイルを移動し、問題を解決することは可能ですが、ここでは説明しません。
- ``widget`` は、利用可能なウィジェット・オブジェクトの1つである必要があります。カスタム・ウィジェットや``SQLFORM.widgets.string.widget``などです。利用可能なウィジェットのリストは後述します。各フィールドの型は、デフォルトのウィジェットを持ちます。
- ``label`` は自動生成されるフォームで、このフィールドに使用するラベルを保持する文字列(または文字列にシリアライズできるもの)です。
- ``comment`` は、このフィールドに関連付けられたコメントを保持し、自動生成されるフォームにおいて入力フィールドの右側に表示される文字列(または文字列にシリアライズできるもの)です。
- ``writable`` もしフィールドがwritableだと、自動生成される作成と更新フォームにおいて編集可能になります。
- ``readable`` もしフィールドがreadableだと、読み取り専用フォームにおいて表示されます。もしフィールドがreadableでもwritableでもない場合、作成と更新フォームにおいてフィールドは表示されません。
- ``update`` は、レコード更新時の、このフィールドに対するデフォルト値になります。
- ``compute`` は、オプション的な関数です。レコードが挿入、または、更新されたとき、compute関数が実行され、フィールドには戻り値が設定されます。レコードはcompute関数に``dict``として渡されます。そのdictには、そのフィールドの現在の値や、他のどのcomputeフィールドの値も含まれていません。
- ``authorize`` は、"upload"フィールドのみで、対応するフィールドのアクセスコントロール要求に使用できます。詳細は、認証と承認のコンテキストにて後述します。
- ``autodelete`` は、アップロードされたファイルを参照するレコードが削除された場合、対応するファイルを削除するかどうかを決定します。"upload"フィールドに対してのみ有効です。
- ``represent`` は、None、または、フィールド値を受け取りフィールド値の代替表現として値を返す関数を指定できます。例:
``
db.mytable.name.represent = lambda name,row: name.capitalize()
db.mytable.other_id.represent = lambda id,row: row.myfield
db.mytable.some_uploadfield.represent = lambda value,row: \
    A('get it', _href=URL('download', args=value))
``:code

``blob``:inxx
"blob"フィールドもまた特別です。デフォルトでは、バイナリデータは、実際のデータベースフィールドに格納される前に、base64でエンコードされ、抽出時にデコードされます。これには、blobフィールドに必要なものより25%余分に記憶領域を使用するというマイナスの効果がありますが、2つの利点があります。平均でweb2pyとデータベースサーバー間のデータ通信量を削減します。そして、通信をバックエンド固有のエスケープ規則から独立させます。

多くのフィールドやテーブル属性は定義された後でも変更可能です：

``
db.define_table('person',Field('name',default=''),format='%(name)s')
db.person._format = '%(name)s/%(id)s'
db.person.name.default = 'anonymous'
``
（テーブルの属性はフィールド名との衝突を避けるために下線を接頭文字として使用している点に注意してください）。

データベース接続に対して、定義されているテーブル一覧を問い合わせることができます。

``tables``:inxx
``
>>> print db.tables
['person']
``:code

定義されているフィールド一覧に関しても、テーブルに問い合わせることができます：

``fields``:inxx
``
>>> print db.person.fields
['id', 'name']
``:code

テーブルの型を問い合わせることができます：

``Table``:inxx
``
>>> print type(db.person)
<class 'gluon.sql.Table'>
``:code

またDAL接続から、次のようにテーブルにアクセスすることができます：
``
>>> print type(db['person'])
<class 'gluon.sql.Table'>
``:code

同様にフィールドの名前から、同等な複数の方法でフィールドにアクセスすることができます：
``
>>> print type(db.person.name)
<class 'gluon.sql.Field'>
>>> print type(db.person['name'])
<class 'gluon.sql.Field'>
>>> print type(db['person']['name'])
<class 'gluon.sql.Field'>
``:code

フィールド名を指定して、定義で設定された属性にアクセスすることができます：
``
>>> print db.person.name.type
string
>>> print db.person.name.unique
False
>>> print db.person.name.notnull
False
>>> print db.person.name.length
32
``:code

親のテーブルやテーブル名、親の接続にもアクセスできます：
``
>>> db.person.name._table == db.person
True
>>> db.person.name._tablename == 'person'
True
>>> db.person.name._db == db
True
``:code

フィールドはメソッドを持っています。後述しますがクエリーを作成する際に使用する場合があります。
フィールドオブジェクトの特別なメソッドは``validate``で、そのフィールドに対するバリデータを呼び出します。

``
print db.person.name.validate('John')
``

これは``(value, error)``のタプルを返します。入力値がバリデータを通った場合、``error``は``None``になります。

### マイグレーション
``migrations``:inxx

``define_table``は、対応するテーブルが存在するかどうかをチェックします。存在しない場合は、それを作成するSQLを生成し、そのSQLを実行します。テーブルが存在しても定義されているものと違うものであれば、そのテーブルを変更するSQLを生成し実行します。フィールドの型を変更し名前は変更してない場合、データを変更しようと試みます(そうしたくない場合は、テーブルを二度、定義し直す必要があります。一度目 はフィールドを除くことによって、そのフィールドを削除するようにweb2pyに指示します。二度目は、新規に定義したフィールドを加えて、web2py に作らせます)。テーブルが存在し現在の定義と一致する場合は、そのままになります。全ての場合において、そのテーブルを表現する``db.person``オブジェクトが作られます。

このような挙動を、ここでは"マイグレーション"と言います。web2pyは全てのマイグレーションとマイグレーションの試みを、"databases/sql.log"ファイルにログとして記録します。

``define_table``の最初の引数は常にテーブルの名前です。他の無名引数はフィールド(Field)です。この関数はまた、"migrate"という省略可能な最後の引数をとることができます。これは、次のように名前によって明示的に参照されなければなりません：
``
>>> db.define_table('person', Field('name'), migrate='person.table')
``:code

migrateの値は、(アプリケーションの"database"フォルダ内の)ファイル名です。このファイルには、このテーブルの内部的なマイグレーション情報がweb2pyによって格納されています。これらのファイルはとても重要で、データベース全体を削除するとき以外には、削除すべきではありません。削除する場合は、".table"ファイルを手動で削除する必要があります。デフォルトでは、migrateはTrueに設定されています。こうすると、web2pyは接続文字列のハッシュからファイル名を生成します。migrateがFalseに設定されていると、マイグレーションは実行されません。web2pyは、データベースにテーブルが存在し、``define_table``に列挙されたフィールドを含んでいると想定します。ベストプラクティスは、明示的な名前をこのmigrateテーブルに与えることです。

同じアプリケーションに、同じmigrateファイルを持つ2つのテーブルが存在することはありません。

DALクラスはまた、"migrate"引数をとります。これは、``define_table``が呼び出されたときのmigrateのデフォルト値を設定します。例 :
``
>>> db = DAL('sqlite://storage.db', migrate=False)
``:code

このようにすると、``db.define_table``がmigrate引数なしに呼び出されたときは常に、migrateのデフォルト値がFalseに設定されます。

接続時にマイグレーションを全てのテーブルに対して無効にすることもできます。

``
db = DAL(...,migrate_enabled=False)
``

これは2つのアプリケーションが同じデータベースを共有する場合に推奨されます。2つの内、1つのアプリケーションでマイグレーションを実行し、もう一方は無効にするべきです。

### 壊れたマイグレーションの修復
``fake_migrate``:inxx

マイグレーションには一般的に2つの問題があり、そして、それらを修復する方法があります。

1つの問題は、SQLite固有のものです。SQLiteは、カラムの型を強制せず、また、カラムを削除することができません。したがって、文字列型のカラムを持っていて、それを削除した場合、それは実際には削除されません。異なる型のカラムを再び加えよう(例えばdatetime)とした場合、(実質的にゴミとなる)文字列が含まれるdatetimeカラムを作ってしまうことになります。web2pyはこれに対してエラーを出しません。なぜならレコードを取得しようとして失敗するまでは、データベースに何が入っているか分からないからです。

もしweb2pyが、レコード選択時にgluon.sql.parse関数でエラーを返す場合、これは上記の問題による、カラム内の壊れたデータの問題になります。

解決方法は、テーブルの全てのレコードを更新し、問題となっているカラムの値をNoneに更新することです。

もう1つの問題は、より一般的ですが、MySQLで典型的に見られるものです。MySQLは、トランザクション中に複数のALTER TABLEを許可しません。これは、web2pyが、複雑なトランザクションを小さなもの(一度に1つのALTER TABLE)に分解しなければならず、一つ一つコミットしなければならないことを意味します。したがって、複雑なトランザクションの一部がコミットされ、別の部分が失敗して、web2pyを壊れた状態にしてしまう可能性があります。なぜトランザクションの一部が失敗するでしょうか？。なぜなら、例えば、テーブルを変更し、文字列カラムを日付カラムに変更しようとしたとき、web2pyがそれらのデータの変換を試みますが、しかしデータ変換ができない場合があるからです。web2pyはどうなるのでしょうか？。データベースに実際に格納したテーブル構造は正確に何なのか、ということについて混乱します。

解決策は、全てのテーブルに対するmigrationを無効にし、次のように、fake migrationを有効にすることです：
``
db.define_table(....,migrate=False,fake_migrate=True)
``:code

これにより、テーブルに関するweb2pyのメタデータは、テーブル定義に従って再構築されます。(マイグレーションが失敗する前のものと後のものの)どれが機能するか、複数のテーブル定義で試してみてください。一旦成功した後は、``fake_migrate=True``属性を削除してください。

マイグレーションの問題を修復しようとする前に、"applications/yourapp/databases/*.table"ファイルのコピーをとっておくのが賢明です。

全テーブルを一度に、マイグレーション問題の修復を行うこともできます。

``
db = DAL(...,fake_migrate_all=True)
``:code

しかし失敗した場合、原因を突き詰めていく手助けにはなりません。

### ``挿入``

テーブルを指定して、レコードを挿入することができます

``insert``:inxx
``
>>> db.person.insert(name="Alex")
1
>>> db.person.insert(name="Bob")
2
``:code

挿入は、挿入したそれぞれのレコードのユニークな"id"値を返します。

テーブルを切捨てることができます。つまり、全てのレコードを削除し、idのカウンタを元に戻します。 

``truncate``:inxx
``
>>> db.person.truncate()
``:code

このとき、もう一度レコードを挿入した場合、カウンタは1から始まります(これはバックエンド固有で、Google NoSQLには適用されません)：
``
>>> db.person.insert(name="Alex")
1
``:code

``bulk_insert``:inxx
web2pyはbulk_insertメソッドも用意しています。
``
>>> db.person.bulk_insert([{'name':'Alex'}, {'name':'John'}, {'name':'Tim'}])
[3,4,5]
``:code

これは、挿入されるフィールドの辞書のリストを受け取り、複数の挿入を一度に実行します。そして挿入された複数のレコードのIDを返します。サポートされているリレーショナルデータベースでは、この関数を使用した場合と、ループさせて個別に挿入をした場合を比べても、特に利点はありません。しかし、Google App Engineでは、大幅な高速化が見込めます。

### ``コミット``と``ロールバック``

いかなる作成、削除、挿入、切捨て、削除、更新操作も、コミットコマンドが発行されるまでは、実際にはコミットされません。

``commit``:inxx
``
>>> db.commit()
``:code

確認のため、新規のレコードを挿入してみましょう：
``
>>> db.person.insert(name="Bob")
2
``:code

そしてロールバックします。つまり、最後にコミットした時点からの全ての操作を無効にします：

``rollback``:inxx
``
>>> db.rollback()
``:code

再び挿入すると、前回の挿入はロールバックされたので、カウンタは再び2に設定されます。
``
>>> db.person.insert(name="Bob")
2
``:code

モデル、ビュー、コントローラ内のコードは、web2pyのコードで次のように囲まれます：
``
try:
     execute models, controller function and view
except:
     rollback all connections
     log the traceback
     send a ticket to the visitor
else:
     commit all connections
     save cookies, sessions and return the page
``:code

web2pyにおいて``コミット``や``ロールバック``を明示的に呼び出すことは、より細かい制御を望まない限り、必要ありません。

### 生のSQL

#### クエリ実行時間の計測

全てのクエリは、web2pyによって実行時間を自動計測します。``db._timings``変数はタプルのリストです。それぞれのタプルはデータベース・ドライバに渡された生のSQLとその実行時間を秒数で持っています。この変数はtoolbarを使用して表示できます。

``
{{=response.toolbar()}}
``

#### ``executesql``

DALは、SQL文を明示的に発行することを可能にします。

``executesql``:inxx
``
>>> print db.executesql('SELECT * FROM person;')
[(1, u'Massimo'), (2, u'Massimo')]
``:code

この場合、戻り値は、DALによって構文解析や変換されることはなく、そのフォーマットは特定のデータベース・ドライバに依存します。selectでの使用は通常は必要ありませんが、インデックスの使用ではより一般的です。
``executesql``は2つのオプション引数をとります：``placeholders``と``as_dict``です。
``placeholders``は、SQLで置換されるオプションの値の配列、もしくはDBドライバでサポートされいれば、SQLの名前付きのプレースホルダーに一致するキーを持つ辞書です。

``as_dict``がTrueに設定されていると、DBドライバによって返される結果のカーソルは、dbフィールド名をキーとして持つ辞書の配列に変換されます。``as_dict = True``で返された結果は、通常のselectに**.as_list()**を適用した時に返されるものと同様のものになります。
``
[{field1: value1, field2: value2}, {field1: value1b, field2: value2b}]
``:code

#### ``_lastsql``

SQLがexecutesqlを用いて手動で実行されても、DALによって生成されたSQLでも、``db._lastsql``でSQLのコードを常に見ることができます。これは、デバッグに便利です：

``_lastdb``:inxx
``
>>> rows = db().select(db.person.ALL)
>>> print db._lastsql
SELECT person.id, person.name FROM person;
``:code

-------
web2pyは"*"演算子を使ったクエリを生成することはありません。web2pyでは常に、明示的にフィールドを選択します。
-------

### ``drop``

最後に、テーブルを削除することができ、全てのデータは失われます：

``drop``:inxx
``
>>> db.person.drop()
``:code

### インデックス

現在DALのAPIは、テーブルにインデックスを作成するコマンドを提供していませんが、これは**executesql**コマンドによって行うことができます。その理由は、既存のインデックスではマイグレーションが複雑になり、それを明示的に扱ったほうが良いからです。インデックスは、クエリで頻繁に使用されているフィールドに対して必要になります。

次に示すのは、SQLiteにおいて[[SQLを使用してインデックスを作成する例 http://www.sqlite.org/lang_createindex.html]]:です：
``
>>> db = DAL('sqlite://storage.db')
>>> db.define_table('person', Field('name'))
>>> db.executesql('CREATE INDEX IF NOT EXISTS myidx ON person (name);')
``:code

他のデータベースの方言は非常に似た構文を持っていますが、オプション的な"IF NOT EXISTS"宣言をサポートしていないことがあります。

### レガシー・データベースとキー付きテーブル

web2pyは、いくつかの条件の下で、レガシー・データベースに接続することができます。

最も簡単な方法は、以下の条件を満たしている時です：
- 各テーブルは、必ず"id"と呼ばれる一意で自動インクリメントした整数フィールドを持つ
- レコードは、必ず"id"フィールドを用いてのみ参照される

-------
既存のテーブルにアクセスする時、つまり、テーブルが現在のアプリケーションのweb2pyによって作成されていない場合、常に``migrate=False``としてください。
-------

レガシー・テーブルが自動インクリメントした整数フィールドを持つが、それが"id"と呼ばれていない場合でも、web2pyはアクセス可能です。しかしこの場合、テーブル定義に、``Field('....','id')``として明示的に含めなければなりません。ここで...は、自動インクリメントした整数フィールドの名前です。
``keyed table``:inxx

最後に、レガシー・テーブルが自動インクリメントidでないプライマリキーを使用していた場合、次の例のように、キー付きテーブルを用いてアクセスすることが可能です：
``
db.define_table('account',
    Field('accnum','integer'),
    Field('acctype'),
    Field('accdesc'),
    primarykey=['accnum','acctype'],
    migrate=False)
``:code

- ``primarykey`` はプライマリキーを構成するフィールド名のリストです。
- 指定されなくても全てのparimarykeyフィールドは``NOT NULL``がセットされています。
- キー付きテーブルは他のキー付きテーブルだけを参照できます。
- 参照するフィールドは``reference tablename.fieldname``フォーマットを使用しなければなりません。
- ``update_record``関数を、キー付きテーブルのRowsに使用することはできません。

-------
ただし現在、これはDB2とMS-SQL、Ingres、Informixに対してのみ利用可能です。しかし、他のデータベースにも簡単に加えることができます。
-------

執筆時点で、primarykey属性が、全てのレガシー・テーブルと、サポートされたデータベース・バックエンドに対して機能することは保障されていません。シンプルにするため可能なら、自動インクリメントしたidフィールドを持つデータベースのビューを作成することを、お勧めします。

### 分散トランザクション
``distributed transactions``:inxx

------
執筆時点では、この機能はPostgreSQL、MySQL、Firebirdに対してのみサポートされています。これらは2相コミットのAPIを公開しているためです。
------

個別のPostgreSQLデータベースに接続する2つ(またはそれ以上)の接続を持っていると仮定します：
``
db_a = DAL('postgres://...')
db_b = DAL('postgres://...')
``:code

モデルやコントローラにおいて、それらを同時にコミットすることが可能です：
``
DAL.distributed_transaction_commit(db_a, db_b)
``:code

失敗した場合は、この関数はロールバックして、``Exception``を発生させます。

コントローラで1つのアクションが返された時、もし2つの別個の接続を持ち、かつ、上記の関数を呼び出していない場合は、web2pyはそれらを個別にコミットします。これは、1つのコミットが成功し、もう一つが失敗するという可能性があることを意味します。分散トランザクションはこのようなことが起こるのを防ぎます。

### 手動アップロード

次のモデルを考えてください：
``
>>> db.define_table('myfile',Field('image','upload'))
``:code

通常、挿入は、SQLFORMやcrudフォーム(SQLFORMの1つ)を介して自動的で処理されます。しかし場合によっては、ファイルシステム上にすでにファイルがあり、プログラムでアップロードしたいことがあります。これは次のような方法で行うことができます：
``
>>> stream = open(filename,'rb')
>>> db.myfile.insert(image=db.myfile.image.store(stream,filename))
``:code

uploadフィールドオブジェクトの``store``メソッドは、ファイルストリームとファイル名を受け取ります。ファイル名はファイルの拡張子(型)を決めるのに使用され、(web2pyのアップロード機構に従って)そのファイルのための新しい仮の名前を作成し、(特に指定がなければuploadsフォルダの下の)その新しい仮のファイルにファイルの内容をロードします。そして、新しい仮のファイル名が返され、``db.myfile``テーブルの``image``フィールドに格納されます。

``.store``の逆は``.retrieve``になります:

``
>>> row = db(db.myfile).select().first()
>>> (filename, stream) = db.myfile.image.retrieve(row.image)
>>> import shutil
>>> shutil.copyfileobj(stream,open(filename,'wb'))
``

### ``Query``, ``Set``, ``Rows``

再び、先ほど定義した(削除した)テーブルを考え、3つのレコードを挿入してみます：
``
>>> db.define_table('person', Field('name'))
>>> db.person.insert(name="Alex")
1
>>> db.person.insert(name="Bob")
2
>>> db.person.insert(name="Carl")
3
``:code

テーブルは変数に格納することができます。例えば、``person``変数として利用することができます：

``Table``:inxx
``
>>> person = db.person
``:code

フィールドも、``name``のように変数に格納することができます。例えば次のようにすることができます：

``Field``:inxx
``
>>> name = person.name
``:code

クエリを(==, !=, <, >, <=, >=, like, belongsのような演算子を用いて)構築し、そのクエリを次のように変数``q``に格納することもできます：

``Query``:inxx
``
>>> q = name=='Alex'
``:code

``db``をクエリとともに呼び出すと、レコードセットを定義していることになります。次のように書いて、それを変数``s``に格納することができます：

``Set``:inxx
``
>>> s = db(q)
``:code

ここまでデータベースクエリが実行されていないことに注意してください。DAL+クエリは、単純にクエリにマッチするdb内のレコードセットを定義するだけです。
web2pyはクエリからどのテーブル(もしくは複数のテーブル)が該当しているかを決めるので、テーブルを実際に指定する必要はありません。

### ``select``

Set``s``に対して、``select``コマンドを用いてレコードを取得することができます：

``Rows``:inxx ``select``:inxx
``
>>> rows = s.select()
``:code

``Row``:inxx
これは、Rowオブジェクトを要素とする``gluon.sql.Rows``クラスの反復可能なオブジェクトを返します。``gluon.sql.Row``オブジェクトは辞書のように振舞いますが、``gluon.storage.Storage``と同様、その要素は属性に関連付けられています。前者は、その値が読み取り専用であるということで後者とは異なります。

Rowsオブジェクトは、selectの結果に対しループを回して、各行の選択したフィールドをプリントできるようにすることができます：
``
>>> for row in rows:
        print row.id, row.name
1 Alex
``:code

上の一連の手順は、次のように1つの文で行うことができます：
``
>>> for row in db(db.person.name=='Alex').select():
        print row.name
Alex
``:code

``ALL``:inxx

selectコマンドは引数をとることが可能です。全ての無名引数は、取得したいフィールド名として解釈されます。例えば、"id"と"name"フィールドを明示的に取得することができます：
``
>>> for row in db().select(db.person.id, db.person.name):
        print row.name
Alex
Bob
Carl
``:code

テーブルのALL属性によって、全てのフィールドを指定することができます：
``
>>> for row in db().select(db.person.ALL):
        print row.name
Alex
Bob
Carl
``:code

dbにはクエリ文字列が何も渡されていないことに注目してください。web2pyは、personテーブルの全てのフィールドが追加情報なしに要求された場合、personテーブルの全てのレコードが要求されていることを理解しています。

同等の代替構文は以下の通りです：
``
>>> for row in db(db.person.id > 0).select():
        print row.name
Alex
Bob
Carl
``:code

そして、person(id > 0)テーブルの全てのレコードが追加情報なしに要求された場合、web2pyはpersonテーブルの全てのフィールドが要求されていることを理解しています。

ひとつのrowに対して

``
row = rows[0]
``

値をいくつかの同等な式で取得できます：

``
>>> row.name
Alex
>>> row['name']
Alex
>>> row('person.name')
Alex
``

後者の構文は、カラムではなく式で選択したい場合に特に便利です。これについては後述します。

また以下のように
``
rows.compact = False
``
表記法を無効にしたり
``
row[i].name
``
有効にして長い表記法にしたり：
``
row[i].person.name
``
できますが、実際にはこのようにする必要は特にありません。

#### ショートカット
``DAL shortcuts``:inxx

DALはコードを簡素化するさまざまなショートカットをサポートしています。具体例を示します：
``
myrecord = db.mytable[id]
``:code

これは、``id``を持つレコードを存在すれば返します。``id``が存在しない場合は、``None``を返します。上記の文は以下と等価です：

``
myrecord = db(db.mytable.id==id).select().first()
``:code

次のようにして、idでレコードを削除することができます：

``
del db.mytable[id]
``:code

これは以下と等価です

``
db(db.mytable.id==id).delete()
``:code

これは、``id``を持つレコードが存在すれば削除します。

次のようにして、レコードを挿入することが可能です：

``
db.mytable[0] = dict(myfield='somevalue')
``:code

これは以下と等価です

``
db.mytable.insert(myfield='somevalue')
``:code

これは、右側の辞書で指定したフィールド値を持つ新規レコードを作成します。

次のようにしてレコードを更新することができます：

``
db.mytable[id] = dict(myfield='somevalue')
``:code

これは以下と等価です

``
db(db.mytable.id==id).update(myfield='somevalue')
``:code

これは、右側の辞書で指定したフィールド値で既存のレコードを更新します。

#### Fetching a ``Row``

もう一つの便利な構文は次のとおりです:

``
record = db.mytable(id)
record = db.mytable(db.mytable.id==id)
record = db.mytable(id,myfield='somevalue')
``:code

上記の構文は、明らかに``db.mytable[id]``と似ていますが、より柔軟性が高く安全です。まず初めに、これはidがint(または``str(id)``がint)であることを確認し、そうでない場合は``None``を返します(例外を発生させることはありません)。レコードが満たす必要のある複数の条件を指定することも可能です。条件に合わない場合は、同様に``None``を返します。

#### 再帰的な``select``s
``recursive selects``:inxx

前述のpersonテーブルと、"person"を参照する新規の"dog"テーブルを考えます：
``
>>> db.define_table('dog', Field('name'), Field('owner',db.person))
``:code

このテーブルの単純なselectは次のようになります：
``
>>> dogs = db(db.dog).select()
``:code

これは以下と等価です

``
>>> dogs = db(db.dog._id>0).select()
``:code

``._id``はテーブルのプライマリキーを参照しています。通常、``db.dog._id``は``db.dog.id``と同じで、この本でもこれを前提にしています。``_id``:inxx

dogsの各Rowに対して、選択したテーブル(dog)のフィールドだけでなく、リンクしたテーブルのフィールドを(再帰的に)取り出すことが可能です：
``
>>> for dog in dogs: print dog.name, dog.owner.name
``:code

ここでは、``dog.owner.name``は、dogsの個々のdogに対して、1回のデータベースのselectを要求するので非効率です。利用可能な時は、再帰的なselectの代わりにjoinを用いることを推奨します。とはいえ、これは個々のレコードにアクセスするときに便利で実用的です。

personによって参照されたdogsを、逆方向でselectすることも可能です：

``
person =  db.person(id)
for dog in person.dog.select(orderby=db.dog.name):
    print person.name, 'owns', dog.name
``:code

この最後の式において、``person.dog``は次のものに対するショートカットになります：

``
db(db.dog.owner==person.id)
``:code

つまり、現在の``person``によって参照される（複数の）``dog``の Set になります。この構文では参照しているテーブルが、参照されたテーブルへ複数の参照を持つ場合は破綻します。そのような時は、より明確に完全なクエリを使用する必要があります。


#### ''ビュー''における``Rows``のシリアライズ

クエリーを含む次の関数がある場合、
``SQLTABLE``:inxx

``
def index()
    return dict(rows = db(query).select())
``:code

selectの結果は、次の構文を使用してビューに表示することができます：
``
{{extend 'layout.html'}}
<h1>Records</h1>
{{=rows}}
``:code

これは以下と等価です：
``
{{extend 'layout.html'}}
<h1>Records</h1>
{{=SQLTABLE(rows)}}
``:code

``SQLTABLE``はrowsを、HTMLのテーブルに変換します。テーブルは、ヘッダにカラム名を、一行毎に各レコードを含んでいます。行は"even"と"odd"クラスで交互にマークされます。内部では、Rowsは最初にSQLTABLEオブジェクト(テーブルとは混同しないでください)へと変換され、シリアライズされます。データベースから抽出した値はまた、そのフィールドに関連付けられたバリデータによってフォマットされ、エスケープされます。(注：ビュー内でdbをこのような方法で使用することは、普通は良いMVCのプラクティスとして考えられていません)

また、SQLTABLEを明示的に呼び出すことも可能で、便利な時があります。

SQLTABLEのコンストラクタは次のようなオプション引数をとります：

- ``linkto`` URL、または、参照フィールドをリンクするために使用される関数(デフォルトはNone) 
- ``upload`` URL、または、アップロードしたファイルのダウンロードを許可するダウンロード関数(デフォルトはNone)
- ``headers`` ヘッダーに使用するフィールド名とそのラベルをマッピングする辞書(デフォルトは``{}``)。一種の命令を指定することもできます。現在は、``headers='fieldname:capitalize'``をサポートしています。
- ``truncate`` テーブルの長い値を切り捨てる文字数(デフォルトは16)
- ``columns`` カラムとして表示するフィールド名のリスト(tablename.fieldnameのフォーマット)。リストされていないものは表示されません(デフォルトは全て)。
- ``**attributes`` 最外部のTABLEオブジェクトに渡される汎用的なヘルパ属性です。

以下が具体例です：
``
{{extend 'layout.html'}}
<h1>Records</h1>
{{=SQLTABLE(rows,
     headers='fieldname:capitalize',
     truncate=100,
     upload=URL('download'))
}}
``:code

``SQLFORM.grid``:inxx ``SQLFORM.smartgrid``:inxx

------
``SQLTABLE``は便利ですが、より多くの機能を必要とする場合があります。``SQLFORM.grid``はSQLTABLEの拡張で、検索、ページング、詳細レコードの表示、作成、編集、削除機能を持ったテーブルを作成します。``SQLFORM.smartgrid``は上記の全ての機能に加えて、参照レコードへアクセスするためのボタンを作成します。
------
以下は``SQLFORM.grid``の使用例です:

``
def index():
    return dict(grid=SQLFORM.grid(query))
``:code

そして対応するビューは:

``
{{extend 'layout.html'}}
{{=grid}}
``

``SQLFORM.grid``と``SQLFORM.smartgrid``は`制約を受けますが、それ以上に強力であるため``SQLTABLE``より優れているといえます。第8章で詳細を説明します。

#### ``orderby``, ``groupby``, ``limitby``, ``distinct``

``select``コマンドは5つのオプション引数をとります：orderby、groupby、limitby、left、cacheです。ここでは、最初の3つについて説明します。

次のように、nameでソートされたレコードを取り出すことができます：

``orderby``:inxx
``
>>> for row in db().select(
        db.person.ALL, orderby=db.person.name):
        print row.name
Alex
Bob
Carl
``:code

nameの逆順でソートされたレコードを取り出すことができます(チルダに注意してください)：
``
>>> for row in db().select(
        db.person.ALL, orderby=~db.person.name):
        print row.name
Carl
Bob
Alex
``:code

ランダムな順番で取り出したレコードを得ることが可能です：
``
>>> for row in db().select(
        db.person.ALL, orderby='<random>'):
        print row.name
Carl
Alex
Bob
``:code

-----
orderby='<random>'の使用はGoogle NoSQL上ではサポートされません。しかし、同じ状況や同様にビルトインが不十分な他の多くの場合、次のようにインポートを使うことができます：
``
import random
rows=db(...).select().sort(lambda row: random.random())
``:code
-----

複数のフィールドに対して、レコードをソートすることができます。これはフィールドを"|"によって連結することで可能です：
``
>>> for row in db().select(
        db.person.ALL, orderby=db.person.name|db.person.id):
        print row.name
Carl
Bob
Alex
``:code

orderbyと一緒にgroupbyを用いて、指定したフィールドの同じ値を持つレコードをグループ化することができます(これはバックエンドに依存します、Google NoSQLでは利用できません)：
``
>>> for row in db().select(
        db.person.ALL,
        orderby=db.person.name, groupby=db.person.name):
        print row.name
Alex
Bob
Carl
``:code

``distinct``:inxx

``distinct=True``の引数を用いて、重複のないレコードだけを選択することができます。フィールドを全て指定して、グループ化するのと同じ効果を持ちます。ただしこの場合、ソートは必要ありません。distinctを用いるとき、全フィールドを選択をしないことは重要です。特に、"id"フィールドを選択しないでください。選択した場合、全レコードが常に重複なしの状態になってしまいます。

以下に例を示します：
``
>>> for row in db().select(db.person.name, distinct=True):
        print row.name
Alex
Bob
Carl
``:code

``distinct``は式にすることもできます。例:
``
>>> for row in db().select(db.person.name,distinct=db.person.name):
        print row.name
Alex
Bob
Carl
``:code

limitbyを使用すると、レコードの一部を選択することができます(以下の例では、0から始まる最初の2つが選択されます)：

``limitby``:inxx
``
>>> for row in db().select(db.person.ALL, limitby=(0, 2)):
        print row.name
Alex
Bob
``:code


#### 論理演算子


クエリは、ANDの二項演算子"&"を使用し、組み合わせることができます：

``and``:inxx ``or``:inxx ``not``:inxx
``
>>> rows = db((db.person.name=='Alex') & (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
4 Alex
``:code

ORの二項演算子"|"も同様です：
``
>>> rows = db((db.person.name=='Alex') | (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
1 Alex
``:code

"!="の二項演算子によってクエリ(またはサブクエリ)を否定できます：
``
>>> rows = db((db.person.name!='Alex') | (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
2 Bob
3 Carl
``:code

または、"~"単項演算子による明示的な否定によっても可能です：
``
>>> rows = db((~db.person.name=='Alex') | (db.person.id>3)).select()
>>> for row in rows: print row.id, row.name
2 Bob
3 Carl
``:code

Pythonにおける"``and``"と"``or``"演算子のオーバーロード制約により、これらはクエリ生成には使用できません。代わりに二項演算子を使用する必要があります。

in-place論理演算子（累積代入文）を使用し、クエリを構築することもできます。

``
>>> query = db.person.name!='Alex'
>>> query &= db.person.id>3
>>> query |= db.person.name=='John'
``

#### ``count``, ``isempty``, ``delete``, ``update``

セット内のレコードをカウントすることができます：

``count``:inxx ``isempty``:inxx

``
>>> print db(db.person.id > 0).count()
3
``:code

``count``はオプションで、デフォルトがFalseの``distinct``引数を指定することが可能です。これは``select``で同じ引数を指定した場合と、非常によく似た動作をします。

テーブルのレコードが空かどうかをチェックしたい場合があります。この場合、カウントするよりも``isempty``メソッドを使うほうがより有効です。

``
>>> print db(db.person.id > 0).isempty()
False
``:code

または、等価の式で：

``
>>> print db(db.person).isempty()
False
``:code

セット内のレコードを削除することができます：

``delete``:inxx
``
>>> db(db.person.id > 3).delete()
``:code

セット内の全てのレコードを更新することができます。更新が必要なフィールドに対応する、名前付き引数を渡します。

``update``:inxx
``
>>> db(db.person.id > 3).update(name='Ken')
``:code

#### 式

更新文で割り当てる値は、式でも可能です。例えば、次のようなモデルで考えてみます
``
>>> db.define_table('person',
        Field('name'),
        Field('visits', 'integer', default=0))
>>> db(db.person.name == 'Massimo').update(
        visits = db.person.visits + 1)
``:code

クエリで使用される値もまた、式にすることができます
``
>>> db.define_table('person',
        Field('name'),
        Field('visits', 'integer', default=0),
        Field('clicks', 'integer', default=0))
>>> db(db.person.visits == db.person.clicks + 1).delete()
``:code

#### ``update_record``

``update_record``:inxx
web2pyでは``update_record``を用いて、すでにメモリ上にある単一のレコードを更新することも可能です。

``
>>> row = db(db.person.id==2).select().first()
>>> row.update_record(name='Curt')
``:code

``update_record``を次のものと混同しないでください

``
>>> row.update(name='Curt')
``:code

その理由は、単一のrowに対して、``update``メソッドはrowオブジェクトを更新しますが、``update_record``のようにデータベースのレコードを更新することはしないからです。

rowの属性を変更（一度に一つずつ）し、それを保存するために引数指定なしで``update_record()``を実行することもできます。

``
>>> row = db(db.person.id > 2).select().first()
>>> row.name = 'Curt'
>>> row.update_record() # saves above change
``:code

#### ``first`` と ``last``
``first``:inxx ``last``:inxx

レコードを保持したRowsオブジェクトが与えられた時、次のようにすることができます：

``
>>> rows = db(query).select()
>>> first_row = rows.first()
>>> last_row = rows.last()
``:code

これは以下のものに相当します。
``
>>> first_row = rows[0] if len(rows)>0 else None
>>> last_row = rows[-1] if len(rows)>0 else None
``:code

#### ``as_dict`` と ``as_list``
``as_list``:inxx ``as_dict``:inxx

Rowオブジェクトは、``as_dict()``メソッドを用いて標準の辞書にシリアライズすることが可能です。Rowsオブジェクトは、**as_list()**メソッドを用いて辞書のリストにシリアライズすることが可能です。例をいくつか示します：
``
>>> rows = db(query).select()
>>> rows_list = rows.as_list()
>>> first_row_dict = rows.first().as_dict()
``:code

これらのメソッドは、Rowsを汎用的なビューに渡したり、Rowsをセッションに格納したりするのに便利です(Rowsオブジェクト自体は、開いているDB接続への参照があるのでシリアライズできません)：
``
>>> rows = db(query).select()
>>> session.rows = rows # not allowed!
>>> session.rows = rows.as_list() # allowed!
``:code

#### ``find``, ``exclude``, ``sort``
``find``:inxx ``exclude``:inxx ``sort``:inxx

2つのselectを実行する必要があり、また前回のselectのサブセットを保持するしている状況がよくあります。この場合、再度データベースにアクセスするのは冗長なことです。``find``、``exclude``、``sort``オブジェクトは、Rowsオブジェクトを操作し、データベースアクセスなしで別のRowsオブジェクト生成を可能にします。具体的に次のようになります:
- ``find`` は、条件でフィルタされた新規のRowsセットを返します。元のものはそのままです。
- ``exclude`` は、条件でフィルタされた新規のRowsセットを返します。それらは元のものから取り除かれます。
- ``sort`` は、条件でソートされた新規のRowsセットを返します。元のものはそのままです。

これら全てのメソッドは、単一の引数として、各々のrowに作用する関数をとります。

これはその使用例です：
``
>>> db.define_table('person',Field('name'))
>>> db.person.insert(name='John')
>>> db.person.insert(name='Max')
>>> db.person.insert(name='Alex')
>>> rows = db(db.person).select()
>>> for row in rows.find(lambda row: row.name[0]=='M'):
        print row.name
Max
>>> print len(rows)
3
>>> for row in rows.exclude(lambda row: row.name[0]=='M'):
        print row.name
Max
>>> print len(rows)
2
>>> for row in rows.sort(lambda row: row.name):
        print row.name
Alex
John
``:code

これらは組み合わせることができます：
``
>>> rows = db(db.person).select()
>>> rows = rows.find(
        lambda row: 'x' in row.name).sort(
            lambda row: row.name)
>>> for row in rows:
        print row.name
Alex
Max
``:code


### その他のメソッド

#### ``update_or_insert``
``update_or_insert``:inxx

同じ値が存在しない場合だけ、挿入したい時があります。
これは以下のように実現できます

``
db.define_table('person',Field('name'),Field('birthplace'))
db.person.update_or_insert(name='John',birthplace='Chicago')
``:code

Chicagoで生まれたJohnが他に存在しない場合だけ挿入されます。

レコードの存在チェックにどのキーを使用するかを指定することができます。例：
``
db.person.update_or_insert(db.person.name=='John',
     name='John',birthplace='Chicago')
``:code

Johnが存在する場合はbirthplaceが更新され、それ以外は挿入されます。

#### ``validate_and_insert``, ``validate_and_update``

``validate_and_insert``:inxx ``validate_and_update``:inxx

この関数は
The function

``
ret = db.mytable.validate_and_insert(field='value')
``:code

以下とほぼ同じ様に動作します。
works very much like

``
id = db.mytable.insert(field='value')
``:code

違いは、挿入の前にバリデータが実行され、通らなかった場合は挿入されないという点です。バリデータを通らなかった場合は``ret.error``にエラー内容が存在します。通った場合は、新規レコードのidは``ret.id``に存在します。通常、バリデータはフォームの処理ロジックで実装されるので、この関数を使用する機会はほとんどないはずです。

同様に

``
ret = db(query).validate_and_update(field='value')
``:code

以下とほぼ同じ様に動作します。

``
num = db(query).update(field='value')
``:code

違いは、更新の前にバリデータが実行される点です。単一のテーブルでだけ動作する点に注意してください。更新されたレコード数は``res.updated``に、エラーは``ret.errors``に存在します。

#### ``smart_query`` (実験的)

以下のような自然言語を使ったクエリを解析したい場合があります

``
name contain m and age greater than 18
``

DALはこのようなタイプのクエリを解析するメソッドを提供します：

``
search = 'name contain m and age greater than 18'
rows = db.smart_query([db.person],search).select()
``

最初の引数はテーブルのリストか検索可能なフィールドでないといけません。検索文字列が無効な場合は``RuntimeError``が発生します。この機能はRESTfulなインターフェース（１０章を参照）を構築する場合や、``SQLFORM.grid``と``SQLFORM.smartgrid``の内部で使用されています。

smartquery検索文字列では、フィールドはフィールド名だけかテーブル名.フィールド名で指定できます。空白を含む文字はダブルクォーテーションで区切られます。

### 計算されたフィールド
``compute``:inxx

DALのフィールドは``compute``フィールドを持つことがあります。これは、Rowオブジェクトを引数にとり、そのフィールドに対する値を返す関数(またはラムダ)である必要があります。新規のレコードが挿入や更新などで変更される時、そのフィールドの値が用意されていない場合、web2pyは``compute``関数を用いて他のフィールドの値から計算しようとします。以下がその例です。
``
>>> db.define_table('item',
        Field('unit_price','double'),
        Field('quantity','integer'),
        Field('total_price',
            compute=lambda r: r['unit_price']*r['quantity']))
>>> r = db.item.insert(unit_price=1.99, quantity=5)
>>> print r.total_price
9.95
``:code

なお、計算された値はdbに格納され、後述する仮想フィールドの場合のように再取得時に計算されることはありません。計算されたフィールドの2つの典型的な活用方法は：
- wikiアプリケーションにおいて、HTMLに加工されたwikiの入力テキストを、リクエスト毎の加工を避けるために格納する
- 検索用に、フィールドの正規化した値を計算し、検索時に使用する

### 仮想フィールド

#### 古い形式の仮想フィールド
``virtualfields``:inxx

仮想フィールドもまた、(前節のように)計算されたフィールドですが、それらは異なります。なぜなら、データベースには格納されず、また、データベースからレコードが取り出されるたびに計算されるという点で仮想であるからです。追加の格納先なしに単純にユーザーコードを用いることができますが、それを用いて検索することはできません。

1つ以上の仮想フィールドを定義するためには、コンテナクラスを定義し、インスタンス化し、テーブルまたは選択に対してリンクさせる必要があります。例えば、次のようなテーブルを考えてください：
``
>>> db.define_table('item',
        Field('unit_price','double'),
        Field('quantity','integer'),
``:code

この時、total_priceという仮想フィールドを次のように定義できます
``
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.item.unit_price*self.item.quantity
>>> db.item.virtualfields.append(MyVirtualFields())
``:code

単一の引数(self)をとるクラスの各メソッドが、新規の仮想フィールドになることに注意してください。フィールドの値は``self.item.unit_price``のように完全パスで参照されます。テーブルは、このクラスのインスタンスをテーブルの``virtualfields``属性に追加することによって、この仮想フィールドにリンクされます。

仮想フィールドも同様に、次のように再帰的なフィールドにアクセスできます
``
>>> db.define_table('item',
        Field('unit_price','double'))
>>> db.define_table('order_item',
        Field('item',db.item),
        Field('quantity','integer'))
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.order_item.item.unit_price \
                * self.order_item.quantity
>>> db.order_item.virtualfields.append(MyVirtualFields())
``:code

再帰的なフィールドは``self.order_item.item.unit_price``にアクセスしていますが、ここで、``self``はループで回されているレコードであることに注意してください。

これらは、結合(JOIN)の結果に対しても作用することができます
``
>>> db.define_table('item',
        Field('unit_price','double'))
>>> db.define_table('order_item',
        Field('item',db.item),
        Field('quantity','integer'))
>>> rows = db(db.order_item.item==db.item.id).select()
>>> class MyVirtualFields(object):
        def total_price(self):
            return self.item.unit_price \
                * self.order_item.quantity
>>> rows.setvirtualfields(order_item=MyVirtualFields())
>>> for row in rows: print row.order_item.total_price
``:code

この場合、どのように構文が異なっているかに注意してください。仮想フィールドは、join選択に属している``self.item.unit_price``と``self.order_item.quantity``の両方にアクセスしています。仮想フィールドはrowsオブジェクトの``setvirtualfields``メソッドを用いてテーブルのrowsに付け加えられます。このメソッドは任意の数の名前付き引数をとります。そして次のように、複数のクラスで定義された複数の仮想フィールドを設定し、それらを複数のテーブルに付け加えることができます：
``
>>> class MyVirtualFields1(object):
        def discounted_unit_price(self):
            return self.item.unit_price*0.90
>>> class MyVirtualFields2(object):
        def total_price(self):
            return self.item.unit_price \
                * self.order_item.quantity
        def discounted_total_price(self):
            return self.item.discounted_unit_price \
                * self.order_item.quantity
>>> rows.setvirtualfields(
        item=MyVirtualFields1(),
        order_item=MyVirtualFields2())
>>> for row in rows:
        print row.order_item.discounted_total_price
``:code

仮想フィールドは遅延(lazy)することが可能です。そのためにやることは、関数を返すようにし、その関数を呼び出すことによってアクセスすることです：
``
>>> db.define_table('item',
        Field('unit_price','double'),
        Field('quantity','integer'),
>>> class MyVirtualFields(object):
        def lazy_total_price(self):
            def lazy(self=self):
                return self.item.unit_price \
                    * self.item.quantity
            return lazy
>>> db.item.virtualfields.append(MyVirtualFields())
>>> for item in db(db.item).select():
        print item.lazy_total_price()
``:code

または、ラムダ関数を用いてより短くします：
``
>>> class MyVirtualFields(object):
        def lazy_total_price(self):
            return lambda self=self: self.item.unit_price \
                * self.item.quantity
``:code


#### 新しい形式の仮想フィールド (実験的)

web2pyは新しくて簡単な仮想フィールドと遅延(lazy)フィールドの定義方法を用意しています。この節の見出しが（実験的）となっているのは、APIがここで述べられているものから一部変更されている可能性があるからです。

前節と同じサンプルで考えてみます。具体的には以下のモデルになります：

``
>>> db.define_table('item',
        Field('unit_price','double'),
        Field('quantity','integer'),
``:code

この時、total_priceという仮想フィールドを次のように定義できます

``
>>> db.item.total_price = Field.Virtual(lambda row: row.unit_price*row.quantity)
``:code

つまり、``Field.Virtual``として``total_price``という新しいフィールドを定義しています。コンストラクタ引数はrowを受け取る関数だけで、計算されたフィールドを返します。

上記で定義された仮想フィールドは、レコードが選択された時点で全てのレコードの値が自動で計算されます。

``
>>> for row in db(db.item).select(): print row.total_price
``

呼び出された時に随時計算される遅延(lazy)フィールドを定義することもできます。例：

``
>>> db.item.total_price = Field.Lazy(lambda row, discount=0.0: \
       row.unit_price*row.quantity*(1.0-discount/100))
``:code

この場合``row.total_price``は値ではなく関数です。この関数は暗黙の型宣言（rowオブジェクトの``self``のように）である``row``を除いて、``Lazy``コンストラクタに渡されます。

上記の例にある遅延(lazy)フィールドは、それぞれの``item``の合計金額を計算します。

``
>>> for row in db(db.item).select(): print row.total_price()
``

そして、``discount`` 率(15%)をオプションで渡します。

``
>>> for row in db(db.item).select(): print row.total_price(15)
``

------
仮想フィールドは他のフィールドと同様の属性（default, readable, requires, etc）を持たず、``db.table.fields``のリストには表示されず、テーブル(TABLE)やグリッド(SQLFORM.grid, SQLFORM.smartgrid)ではデフォルトで表示されない点に気をつけてください。
------

###  1対多のリレーション
``one to many``:inxx

web2pyのDALを用いて1対多のリレーションをどのように実装するかを説明するために、"person"テーブルを参照するもう1つの"dog"テーブルを定義します。"person"もここで再定義します：
``
>>> db.define_table('person',
                    Field('name'),
                    format='%(name)s')
>>> db.define_table('dog',
                    Field('name'),
                    Field('owner', db.person),
                    format='%(name)s')
``:code

"dog"テーブルは、犬の名前(name)と犬の飼い主(owner)という2つのフィールドを持ちます。フィールドの型が他のテーブルの時、そのフィールドが他のテーブルをそのidによって参照することを意図しています。実際、実在の型の値を出力及び取得することができます：
``
>>> print db.dog.owner.type
reference person
``:code

ここで、Alexの飼っている2匹と、Bobが飼っている1匹の計3匹の犬を挿入します：
``
>>> db.dog.insert(name='Skipper', owner=1)
1
>>> db.dog.insert(name='Snoopy', owner=1)
2
>>> db.dog.insert(name='Puppy', owner=2)
3
``:code

ほかのテーブルと同じように、テーブルをselectすることができます：
``
>>> for row in db(db.dog.owner==1).select():
        print row.name
Skipper
Snoopy
``:code

犬は飼い主の参照を持っているため、飼い主は複数の犬を持つことができます。したがって、personテーブルのレコードはこの時、dogという新規の属性を取得します。これにより、全ての飼い主に対してループを回して、それらの犬を取得することが簡単にできるようになります：

``referencing``:inxx
``
>>> for person in db().select(db.person.ALL):
        print person.name
        for dog in person.dog.select():
            print '    ', dog.name
Alex
     Skipper
     Snoopy
Bob
     Puppy
Carl
``:code

#### 内部結合(Inner Joins)

同様の結果を得るための別の方法は、join、具体的には、INNER JOINを用いることです。web2pyは、次の例のようにクエリが2つ以上のテーブルをリンクする時に、joinを自動で透過的に実行します。

``Rows``:inxx ``inner join``:inxx ``join``:inxx
``
>>> rows = db(db.person.id==db.dog.owner).select()
>>> for row in rows:
        print row.person.name, 'has', row.dog.name
Alex has Skipper
Alex has Snoopy
Bob has Puppy
``:code

web2pyがjoinを行って、rowsが、一緒にリンクされた各テーブル由来の2つのレコードを含んでいることを見てください。2つのレコードは競合する名前のフィールドを持つ可能性があるので、rowからのフィールド値を取り出すときに、テーブルを指定する必要があります。つまり、次のことをする前は：
``
row.name
``:code

これが飼い主の名前なのか、犬の名前なのかは明らかでした。joinの結果においては、次のようにより明示的なものにする必要があります：
``
row.person.name
``:code

or:
``
row.dog.name
``:code

INNER JOINには別の構文もあります：
``
>>> rows = db(db.person).select(join=db.dog.on(db.person.id==db.dog.owner))
>>> for row in rows:
    print row.person.name, 'has', row.dog.name
Alex has Skipper
Alex has Snoopy
Bob has Puppy
``:code

出力結果は同じですが、生成されるSQLは異なる可能性があります。後者の構文は同じテーブルが2回結合されて別名が使用された場合に、それぞれのテーブルを明確に指定できます。

``
>>> db.define_table('dog',
        Field('name'),
        Field('owner1',db.person),
        Field('owner2',db.person))
>>> rows = db(db.person).select(
    join=[db.person.with_alias('owner1').on(db.person.id==db.dog.owner1).
          db.person.with_alias('owner2').on(db.person.id==db.dog.owner2)])
``

``join``の値には、``db.table.on(...)``のリストを使用できます。

#### 左外部結合(Left Outer Join)

Carlは犬を飼っていないので、上記の表には現れませんでした。飼い主(犬を飼っている、いないに関わらず)と犬(もし飼われていれば)を選択しようとした場合、LEFT OUTER JOINを実行する必要があります。これは、selectコマンドの"left"引数を用いて行うことができます。以下がその例です：

``Rows``:inxx ``left outer join``:inxx ``outer join``:inxx
``
>>> rows=db().select(
        db.person.ALL, db.dog.ALL,
        left=db.dog.on(db.person.id==db.dog.owner))
>>> for row in rows:
        print row.person.name, 'has', row.dog.name
Alex has Skipper
Alex has Snoopy
Bob has Puppy
Carl has None
``:code

ここで：
``
left = db.dog.on(...)
``:code

これはleft joinクエリを行います。``db.dog.on``の引数は、joinに必要な条件になります(上述のinner joinで使用したものと同じです)。left joinの場合、どのフィールドを選択するかは明示的にする必要があります。

複数のleft joinをする場合は、``db.mytable.on(...)``のリストかタプルを``left``属性に渡すことで組み合わせることができます。

#### グループ化とカウント

結合(join)を行うとき、特定の条件に従って行をグループ化し、カウントしたい場合があります。例えば、各飼い主が飼っている犬の数をカウントする場合です。web2pyではこれも同様に行うことができます。初めに、カウント演算子が必要になります。第2に、personテーブルとdogテーブルをその飼い主(owner)によってjoinします。第3に、全ての行(person + dog)を選択し、person毎にそれらをグループ化して、グループ化している最中にカウントします：

``grouping``:inxx
``
>>> count = db.person.id.count()
>>> for row in db(db.person.id==db.dog.owner).select(
        db.person.name, count, groupby=db.person.name):
        print row.person.name, row[count]
Alex 2
Bob 1
``:code

(組み込みの)カウント演算子がフィールドのように用いられていることに注意してください。ここでの唯一の問題は、どのように情報を取り出すかにあります。各行は明らかに1人のpersonとカウントを含んでいます。しかしカウントは、personのフィールドではなく、テーブルでもありません。これ（カウントオブエクト）はどこに行くのでしょうか？。クエリ式自体と同じキーを持つ、レコードを表現するストレージオブジェクトになります。

### Many to many
``many-to-many``:inxx
前述の例では、1匹の犬は1人の飼い主(owner)を持つけれど、1人の飼い主は多くの犬を飼えるようにしました。AlexとCurtによって飼われているSkipperはどうなるのでしょうか？これには多対多のリレーションが必要です。そしてこれは、所有(ownership)関係で1人の飼い主と1匹の犬をリンクする中間テーブルを介して実現されます。

どのようにそれを行うかを以下に示します：
``
>>> db.define_table('person',
                    Field('name'))
>>> db.define_table('dog',
                    Field('name'))
>>> db.define_table('ownership',
                    Field('person', db.person),
                    Field('dog', db.dog))
``:code

これまでの所有(ownership)関係は次のように書き換えることができます：
``
>>> db.ownership.insert(person=1, dog=1) # Alex owns Skipper
>>> db.ownership.insert(person=1, dog=2) # Alex owns Snoopy
>>> db.ownership.insert(person=2, dog=3) # Bob owns Puppy

``:code

今度は、CurtがSkipperを一緒に飼っているという、新しいリレーションを加えることができます：
``
>>> db.ownership.insert(person=3, dog=1) # Curt owns Skipper too

``:code

3方向のテーブル間のリレーションを持っているので、操作を実行する上で、次のような新規のSetを定義することは便利です：
``
>>> persons_and_dogs = db(
        (db.person.id==db.ownership.person) \
        & (db.dog.id==db.ownership.dog))
``:code

これで新規のSetから、全ての飼い主と彼らの犬を簡単に選択できます：
``
>>> for row in persons_and_dogs.select():
        print row.person.name, row.dog.name
Alex Skipper
Alex Snoopy
Bob Puppy
Curt Skipper
``:code

同様に、Alexが飼っている全ての犬を検索することもできます：
``
>>> for row in persons_and_dogs(db.person.name=='Alex').select():
        print row.dog.name
Skipper
Snoopy
``:code

そして、Skipperの飼い主も検索することができます：
``
>>> for row in persons_and_dogs(db.dog.name=='Skipper').select():
        print row.person.name
Alex
Curt
``:code

多対多の簡易な代替案はタグ付けです。タグ付けは``IS_IN_DB``のコンテキストで後述します。タグ付けは、Google App Engine NoSQLのようなJOINをサポートしていないデータベース・バックエンドでも機能します。

### 多対多、``list:<type>``、``contains``
``list:string``:inxx
``list:integer``:inxx
``list:reference``:inxx
``contains``:inxx
``multiple``:inxx
``tags``:inxx

web2pyは、以下の特別なフィールド型を用意しています：

``
list:string
list:integer
list:reference <table>
``:code

これらはそれぞれ、文字列、整数、参照のリストを収容します。

Google App Engine NoSQLでは、``list:string``は``StringListProperty``にマッピングされ、他の2つは、``ListProperty(int)``にマッピングされます。リレーショナル・データベースでは、``|``によって区切られた項目のリストを持つテキストフィールドにマッピングされます。例えば、``[1,2,3]``は``|1|2|3|``にマッピングされます。

文字列のリストでは、項目内の任意の``|``が``||``に置換されるように項目はエスケープされます。いずれにせよ、これは内部表現でありユーザーに対しては透過的です。

次の例のように``list:string``を用いることができます：

``
>>> db.define_table('product',
        Field('name'),
        Field('colors','list:string'))
>>> db.product.colors.requires=IS_IN_SET(('red','blue','green'))
>>> db.product.insert(name='Toy Car',colors=['red','green'])
>>> products = db(db.product.colors.contains('red')).select()
>>> for item in products:
        print item.name, item.colors
Toy Car ['red', 'green']
``:code

``list:integer``も同様に機能します。ただし、項目は整数でなければなりません。

例のごとく、この要求は、``insert``レベルではなく、フォームレベルで強制されます。

------
``list:<type>``フィールドにおいて、``contains(value)``演算子は``value``が含まれているかをリストに対してチェックする、通常でないクエリにマッピングされます。``contains``演算子は、標準の``string``と``text``フィールドでも機能し、``LIKE '%value%'``にマッピングされます。
------

``list:reference``と``contains(value)``演算子は、多対多リレーションの非正規化にとって特に有用です。以下がその例です。

``
>>> db.define_table('tag',Field('name'),format='%(name)s')
>>> db.define_table('product',
        Field('name'),
        Field('tags','list:reference tag'))
>>> a = db.tag.insert(name='red')
>>> b = db.tag.insert(name='green')
>>> c = db.tag.insert(name='blue')
>>> db.product.insert(name='Toy Car',tags=[a, b, c])
>>> products = db(db.product.tags.contains(b)).select()
>>> for item in products:
        print item.name, item.tags
Toy Car [1, 2, 3]
>>> for item in products:
        print item.name, db.product.tags.represent(item.tags)
Toy Car red, green, blue
``:code

``list:reference``のtagフィールドは、次のようなデフォルトの制約を取得することに注意してください

``
requires = IS_IN_DB(db,'tag.id',db.tag._format,multiple=True)
``:code

これは、フォームにおいて``SELECT/OPTION``の複数ドロップボックスを生成します。

また、このフィールドはデフォルトで、フォーマットした参照のカンマ区切りリストのように、参照リストを表現する``represent``属性を取得することにも注意してください。これは、フォームと``SQLTABLE``の読み込み時に利用されます。

-----
``list:reference``はデフォルトのバリデータとデフォルトの表現を持つ一方、``list:integer``と``list:string``は持ちません。したがって、これら2つをフォームで利用する場合、``IS_IN_SET``か``IS_IN_DB``バリデータが必要になります。
-----


### その他の演算子

web2pyには、同等なSQL演算子にアクセスするためのAPIを提供する演算子があります。"log"という別のテーブルを定義してみます。そのテーブルでは、セキュリティ・イベントとそのevent_timeと重大度(severity)を格納するようにします。ここで重大度(severity)は整数です。

``date``:inxx ``datetime``:inxx ``time``:inxx
``
>>> db.define_table('log', Field('event'),
                           Field('event_time', 'datetime'),
                           Field('severity', 'integer'))
``:code

前回と同様、イベントとして、"port scan"と "xss injection"と"unauthorized login"を数個挿入します。例として、同じevent_timeを持つが重大度(それぞれ1,2,3)は異なるイベントをログとして記録します。
``
>>> import datetime
>>> now = datetime.datetime.now()
>>> print db.log.insert(
        event='port scan', event_time=now, severity=1)
1
>>> print db.log.insert(
        event='xss injection', event_time=now, severity=2)
2
>>> print db.log.insert(
        event='unauthorized login', event_time=now, severity=3)
3
``:code

#### ``like``, ``startswith``, ``contains``, ``upper``, ``lower``
``like``:inxx ``startswith``:inxx
``contains``:inxx ``upper``:inxx ``lower``:inxx

フィールドは、文字列を照合するためのlike演算子を持っています：

``
>>> for row in db(db.log.event.like('port%')).select():
        print row.event
port scan
``:code

ここで、"port%"は"port"から始まる文字列を示しています。パーセント記号文字"%"は、"任意の文字列"を意味するワイルドカード文字です。

web2pyはまた、いくつかのショートカットを提供しています：

``
db.mytable.myfield.startswith('value')
db.mytable.myfield.contains('value')
``:code

これは、それぞれ以下に相当します

``
db.mytable.myfield.like('value%')
db.mytable.myfield.like('%value%')
``:code

``contains``は、前節で説明したように、``list:<type>``フィールドに対して特別な意味を持つことに注意してください。

``contains``メソッドは値をリストで渡すことや、ブーリアン型の変数``all``をオプションで指定し全ての値を含むレコードだけを検索することもできます。

``
db.mytable.myfield.contains(['value1','value2'], all=True)
``
または、リストのどれかの値を含む場合は次の通りです。
``
db.mytable.myfield.contains(['value1','value2'], all=false)
``

同様に、フィールドの値を大文字、または、小文字に変換するために``upper``と``lower``メソッドを使用することができます。さらに、like演算子と組み合わせることができます。

``upper``:inxx ``lower``:inxx
``
>>> for row in db(db.log.event.upper().like('PORT%')).select():
        print row.event
port scan
``:code

#### ``year``, ``month``, ``day``, ``hour``, ``minutes``, ``seconds``
``hour``:inxx ``minutes``:inxx ``seconds``:inxx ``day``:inxx ``month``:inxx ``year``:inxx

dateとdatetimeフィールドはday、month、yearメソッドを持ちます。datetimeおよびtimeフィールドは、hour、minutes、secondsメソッドを持ちます。以下がその例です：

``
>>> for row in db(db.log.event_time.year()==2009).select():
        print row.event
port scan
xss injection
unauthorized login
``:code

#### ``belongs``

SQLのIN演算子は、belongsメソッドを介して実現されます。このメソッドは、フィールドの値が指定したセット(タプルのリスト)に所属している時にtrueを返します。

``belongs``:inxx
``
>>> for row in db(db.log.severity.belongs((1, 2))).select():
        print row.event
port scan
xss injection
``:code

DALはまた、belongs演算子の引数にネストしたselectを許しています。唯一の注意点は、ネストしたselectは``select``ではなく``_select``でなければならず、フィールドは1つだけ、明示的にセットを定義するものを選択する必要があります。

``nested select``:inxx
``
>>> bad_days = db(db.log.severity==3)._select(db.log.event_time)
>>> for row in db(db.log.event_time.belongs(bad_days)).select():
        print row.event
port scan
xss injection
unauthorized login
``:code

#### ``sum``, ``min``, ``max`` and ``len``

``sum``:inxx ``min``:inxx ``max``:inxx
前回は、カウント演算子をレコードのカウントに使用しました。同様にサム(sum)演算子を、レコードのグループから特定のフィールドの値を足す(sum)ことに使用することができます。カウントの場合と同様に、サムの結果は格納オブジェクトから取り出すことができます：
``
>>> sum = db.log.severity.sum()
>>> print db().select(sum).first()[sum]
6
``:code

同様に``min``と``max``で、選択されたレコードの最小値と最大値を取り出せます。

``
>>> max = db.log.severity.max()
>>> print db().select(max).first()[max]
3
``:code

``.len()``は文字、テキスト、またはブーリアン型のフィールドの長さを計算します。

式を組み合わせてより複雑な式を作ることができます。この例では、logテーブルのseverity文字フィールドの長さに1を加えた結果を合計しています。

``
>>> sum = (db.log.severity.len()+1).sum()
>>> print db().select(sum).first()[sum]
``:code

#### サブストリング

サブストリングの値を参照した式を作成することができます。例えば、最初の3文字の名前が同じ犬をグループ化でき、各グループから1つだけ選択します。

``
db(db.dog).select(distinct = db.dog.name[:3])
``:code


#### ``coalesce``と``coalesce_zero``によるデフォルト値

データベースから値を取得したいが、NULLの時はデフォルトの値が必要な場合があります。SQLではこの目的のために``COALESCE``が提供されています。web2pyでは等価の``coalesce``メソッドを提供します。

``
>>> db.define_table('sysuser',Field('username'),Field('fullname'))
>>> db.sysuser.insert(username='max',fullname='Max Power')
>>> db.sysuser.insert(username='tim',fullname=None)
print db(db.sysuser).select(db.sysuser.fullname.coalesce(db.sysuser.username))
"COALESCE(sysuser.fullname,sysuser.username)"
Max Power
tim
``

数学的な式を計算したいが、本来ゼロであるべきフィールドにNoneがセットされている場合もあります。``coalesce_zero``はクエリでNoneのデフォルト値にゼロをセットする手助けをします。

``
>>> db.define_table('sysuser',Field('username'),Field('points'))
>>> db.sysuser.insert(username='max',points=10)
>>> db.sysuser.insert(username='tim',points=None)
>>> print db(db.sysuser).select(db.sysuser.points.coalesce_zero().sum())
"SUM(COALESCE(sysuser.points,0))"
10
``

### 生SQLの生成
``raw SQL``:inxx

SQLは生成したいが実行したくないことがあります。web2pyでこれを行うのは簡単です。なぜならデータベースのIOを実行する全てのコマンドは、単純に実行しようとしたSQLを実行せずに返す、同等のコマンドを持つからです。これらのコマンドは、機能するものと同じ名前と構文を持ちますが、アンダースコアで始まります：

これは``_insert`` ``_insert``:inxxです：
``
>>> print db.person._insert(name='Alex')
INSERT INTO person(name) VALUES ('Alex');
``:code

これは``_count`` ``_count``:inxxです
``
>>> print db(db.person.name=='Alex')._count()
SELECT count(*) FROM person WHERE person.name='Alex';
``:code

これは``_select`` ``_select``:inxxです
``
>>> print db(db.person.name=='Alex')._select()
SELECT person.id, person.name FROM person WHERE person.name='Alex';
``:code

これは``_delete`` ``_delete``:inxxです
``
>>> print db(db.person.name=='Alex')._delete()
DELETE FROM person WHERE person.name='Alex';
``:code

最後に、これは``_update`` ``_update``:inxxです
``
>>> print db(db.person.name=='Alex')._update()
UPDATE person SET  WHERE person.name='Alex';
``:code

-----
さらに、``db._lastsql``を用いて、直近のSQLコードを返すことができます。これは、executesqlを用いて手動で実行されたSQLでも、DALによって生成されたSQLでも可能です。
-----

### データのエクスポートとインポート
``export``:inxx ``import``:inxx

#### CSV(一度に1つのテーブル)

DALのRowsオブジェクトが文字列に変換される時、自動的にCSV形式にシリアライズされます：

``csv``:inxx
``
>>> rows = db(db.person.id==db.dog.owner).select()
>>> print rows
person.id,person.name,dog.id,dog.name,dog.owner
1,Alex,1,Skipper,1
1,Alex,2,Snoopy,1
2,Bob,3,Puppy,2
``:code

単一のテーブルをCSV形式にシリアライズして、"test.csv"ファイルに格納することができます：
``
>>> open('test.csv', 'w').write(str(db(db.person.id).select()))
``:code

そして、次のようにして簡単にそれを読み取ることができます：
``
>>> db.person.import_from_csv_file(open('test.csv', 'r'))
``:code

インポートする時に、web2pyはCSVのヘッダにあるフィールド名を探します。この例では、"person.name"と"person.id"という2つのカラムを見つけます。"person"という接頭辞と、"id"というフィールドは無視されます。そして全てのレコードは追加され、新しいIDが割り当てられます。これら両方の操作はappadminのWeb・インターフェースを介して行うことができます。

#### CSV(全てのテーブルを一度に)

web2pyでは、次の2つのコマンドでデータベース全体をバックアップ／復元することができます：

エクスポートするには：
``
>>> db.export_to_csv_file(open('somefile.csv', 'wb'))
``:code

インポートするには：
``
>>> db.import_from_csv_file(open('somefile.csv', 'rb'))
``:code

このメカニズムは、インポートしたデータベースがエクスポートするデータベースと異なるタイプのものでも使用することができます。データは"somefile.csv"にCSVファイルとして格納されます。このファイルでは、各テーブルは、テーブル名を示す一つの行と、フィールド名を持つもう一つの行から始まります：
``
TABLE tablename
field1, field2, field3, ...
``:code

2つのテーブルは``\r\n\r\n``で区切られます。ファイルは次の行で終わります
``
END
``:code

このファイルには、アップロードファイルがデータベースに格納されていない限り含まれません。どのような場合でも、"uploads"フォルダを個別に圧縮することは十分に簡単です。

インポートする時、新規のレコードはデータベースが空でない場合に、データベースに追加されます。一般に新しくインポートしたレコードは、元の(保存した)レコードと同じレコードidを持つことはありません。しかしweb2pyは参照も復元するので、idの値が変化しても参照が機能しなくなることはありません。

もしテーブルに"uuid"と呼ばれるフィールドが含まれる場合、そのフィールドは重複を識別するために使用されます。また、インポートしたレコードが既存のレコードと同じ"uuid"を持つ場合、既存のレコードは更新されます。

#### CSVとリモート・データベースの同期

次のモデルを考えてください：
``
db = DAL('sqlite:memory:')
db.define_table('person',
    Field('name'),
    format='%(name)s')
db.define_table('dog',
    Field('owner', db.person),
    Field('name'),
    format='%(name)s')

if not db(db.person).count():
    id = db.person.insert(name="Massimo")
    db.dog.insert(owner=id, name="Snoopy")
``:code

各レコードは、IDによって識別され、そのIDによって参照されます。別々にインストールしたweb2pyによって利用されるデータベースの2つのコピーを持っているなら、IDは各データベースにおいてのみユニークで、データベース全体ではユニークではありません。これは、異なるデータベースからレコードをマージする時に問題になります。

データベース全体でレコードを一意に識別できるようにするには、レコードを次のようにする必要があります：

- 一意のID(UUID)を持たせる
- event_timeを持たせる(複数のコピーがある場合、より最近のものを判別するために)
- idの代わりにUUIDで参照する

これはweb2pyを変更することなく実現できます。以下にどのようにするかを示します：

**1.** 上記のモデルを次のように変更します：

``
db.define_table('person',
    Field('uuid', length=64, default=lambda:str(uuid.uuid4())),
    Field('modified_on', 'datetime', default=now),
    Field('name'),
    format='%(name)s')

db.define_table('dog',
    Field('uuid', length=64, default=lambda:str(uuid.uuid4())),
    Field('modified_on', 'datetime', default=now),
    Field('owner', length=64),
    Field('name'),
    format='%(name)s')

db.dog.owner.requires = IS_IN_DB(db,'person.uuid','%(name)s')

if not db(db.person.id).count():
    id = uuid.uuid4()
    db.person.insert(name="Massimo", uuid=id)
    db.dog.insert(owner=id, name="Snoopy")
``:code

-------
上記のテーブル定義では、2つのuuidフィールドのデフォルト値が（文字に変換された）UUIDを返すラムダ関数によってセットされています。ラムダ関数はそれぞれのレコードが挿入される際に呼び出され、複数のレコードが一つのトランザクションで挿入された場合でも、ユニークなUUIDを取得するようにします。
-------

**2.** データベースをエクスポートするコントローラの関数を作成します：

``
def export():
    s = StringIO.StringIO()
    db.export_to_csv_file(s)
    response.headers['Content-Type'] = 'text/csv'
    return s.getvalue()
``:code

**3.** 他のデータベースが保存したコピーをインポートし、レコードを同期するコントローラの関数を作成します：

``
def import_and_sync():
    form = FORM(INPUT(_type='file', _name='data'), INPUT(_type='submit'))
    if form.process(session=None).accepted:
        db.import_from_csv_file(form.vars.data.file,unique=False)
        # for every table
        for table in db.tables:
            # for every uuid, delete all but the latest
            items = db(db[table]).select(db[table].id,
                       db[table].uuid,
                       orderby=db[table].modified_on,
                       groupby=db[table].uuid)
            for item in items:
                db((db[table].uuid==item.uuid)&\
                   (db[table].id!=item.id)).delete()
    return dict(form=form)
``:code

このURLは外部から接続されることを想定しているので、``session=None``がCSRF保護を無効にしている点に注意してください。

**4.** uuidによる検索を高速化するためにインデックスを手動で作成します。

ただし、ステップ2と3は全てのデータベースモデルで機能します。この例では固有のものはないからです。

``XML-RPC``:inxx
別の方法として、XML-RPCを用いてファイルをエクスポート/インポートすることができます。

レコードがアップロードしたファイルを参照する場合、uploadsフォルダの中身もまたエクスポート/インポートする必要があります。ただし、ファイルはUUIDで既にラベル付けされているので、名前の衝突と参照を心配する必要はありません。

#### HTML/XMLの(一度に一つのテーブル)

``DALRows objects``:inxx
DALのRowsオブジェクトはまた、(ヘルパのように)自身をXML/HTMLへとシリアライズする``xml``メソッドを持ちます：

``HTML``:inxx

``
>>> rows = db(db.person.id > 0).select()
>>> print rows.xml()
<table>
  <thead>
    <tr>
      <th>person.id</th>
      <th>person.name</th>
      <th>dog.id</th>
      <th>dog.name</th>
      <th>dog.owner</th>
    </tr>
  </thead>
  <tbody>
    <tr class="even">
      <td>1</td>
      <td>Alex</td>
      <td>1</td>
      <td>Skipper</td>
      <td>1</td>
    </tr>
    ...
  </tbody>
</table>
``:code

``DALRows custom tags``:inxx
DALのRowsを、カスタムタグを持った他のXMLフォーマットへとシリアライズしたい場合は、普遍的なタグヘルパや*表記を使用して簡単に行うことができます：
``XML``:inxx

``
>>> rows = db(db.person.id > 0).select()
>>> print TAG.result(*[TAG.row(*[TAG.field(r[f], _name=f) \
          for f in db.person.fields]) for r in rows])
<result>
  <row>
    <field name="id">1</field>
    <field name="name">Alex</field>
  </row>
  ...
</result>
``:code

#### データ表現

``export_to_csv_file``:inxx
``export_to_csv_file``関数はキーワード引数``represent``を持ちます。Trueの場合、データのエクスポート中に、生のデータの代わりに、カラムの``represent``関数を用います。

``colnames``:inxx
この関数はまた、エクスポートしたいカラムの名前のリストを保持するキーワード引数``colnames``を持ちます。デフォルトでは全てのカラムになります。

``export_to_csv_file``と``import_from_csv_file``の両方とも、CSVの構文解析機に保存/読み込み先のファイルのフォーマットを知らせる次のキーワード引数を持ちます：
- ``delimiter``: 値の区切り文字の指定(デフォルトは',')
- ``quotechar``: 文字列値を引用符で囲むために使用する文字(デフォルトはダブルクォート)
- ``quoting``: 引用符の体系(デフォルトは``csv.QUOTE_MINIMAL``)

ここでは、いくつか使用例を示します：
``
>>> import csv
>>> db.export_to_csv_file(open('/tmp/test.txt', 'w'),
        delimiter='|',
        quotechar='"',
        quoting=csv.QUOTE_NONNUMERIC)
``:code

これは以下のようなレンダリングになります
``
"hello"|35|"this is the text description"|"2009-03-03"
``:code

より詳細な情報は公式のPythonドキュメントを参照してください。``quoteall``:cite

### 選択のキャッシュ

selectメソッドではcache引数を取ります。これはデフォルトではNoneです。キャッシュの利用の際は、ここにタプルを設定する必要があります。このタプルの最初の要素はキャッシュモデルで(cache.ram、chace.diskなど)、第2の要素は秒単位の有効期限です。

次の例では、前に定義したdb.logテーブルに対するselectをキャッシュするコントローラを設定しています。実際のselectでは60秒間隔より頻繁に、バックエンドのデータベースからデータを取り出すことはなく、cache.ramに結果を格納します。このコントローラへの次の呼び出しが、最終のデータベースIOから60秒以内に発生する場合、cache.ramから前回のデータが単純に取り出されます。

``cache select``:inxx
``
def cache_db_select():
    logs = db().select(db.log.ALL, cache=(cache.ram, 60))
    return dict(logs=logs)
``:code

-------
``select``の結果は複雑で、pickle化できないオブジェクトです。したがって、これらはsessionに格納することはできず、ここで説明したもの以外はどの方法でもキャッシュすることはできません。
-------

### 自己参照と別名

``self reference``:inxx
``alias``:inxx
自分自身を参照するフィールドを持つテーブルを定義することも可能ですが、通常の表記方法ではうまくいきません。次のコードは、``db.person``変数を定義する前に使用しいているので間違っています：
``
db.define_table('person',
    Field('name'),
    Field('father_id', db.person),
    Field('mother_id', db.person))
``:code

解決策は次のような代替表記を使用することです
``reference table``:inxx
``
db.define_table('person',
    Field('name'),
    Field('father_id', 'reference person'),
    Field('mother_id', 'reference person'))
``:code

実際、``db.tablename``と``"reference tablename"``は同じフィールドの型になります。

``with_alias``:inxx
テーブルが自分自身を参照する場合、SQLの"AS"キーワードの使用なしに、JOINを実行して、personとその親(parents)を選択することは不可能です。これは、web2pyにおいて``with_alias``を用いて実現されます。以下がその例です。
``
>>> Father = db.person.with_alias('father')
>>> Mother = db.person.with_alias('mother')
>>> db.person.insert(name='Massimo')
1
>>> db.person.insert(name='Claudia')
2
>>> db.person.insert(name='Marco', father_id=1, mother_id=2)
3
>>> rows = db().select(db.person.name, Father.name, Mother.name,
      left=(Father.on(Father.id==db.person.father_id),
            Mother.on(Mother.id==db.person.mother_id)))
>>> for row in rows:
        print row.person.name, row.father.name, row.mother.name
Massimo None None
Claudia None None
Marco Massimo Claudia
``:code

以下のものを区別して選択していることに注意してください：
- "father_id": "person"テーブルにおいて使用されるフィールド名
- "father": 上記のフィールドによって参照されるテーブルのために使用する別名。これはデータベースとやり取りされます。
- "Father": その別名を参照するためのweb2pyによって使用される変数

僅かな違いなので、それら3つに同じ名前をつけても間違いではありません：
``
db.define_table('person',
    Field('name'),
    Field('father', 'reference person'),
    Field('mother', 'reference person'))
>>> father = db.person.with_alias('father')
>>> mother = db.person.with_alias('mother')
>>> db.person.insert(name='Massimo')
1
>>> db.person.insert(name='Claudia')
2
>>> db.person.insert(name='Marco', father=1, mother=2)
3
>>> rows = db().select(db.person.name, father.name, mother.name,
      left=(father.on(father.id==db.person.father),
            mother.on(mother.id==db.person.mother)))
>>> for row in rows:
        print row.person.name, row.father.name, row.mother.name
Massimo None None
Claudia None None
Marco Massimo Claudia
``:code

しかし、正しいクエリを構築するには、この区別を明確にすることが重要です。

### 高度な機能

#### テーブル継承
``inheritance``:inxx

他のテーブルの全てのフィールドを含んだテーブルを、作成することが可能です。これは、他のテーブルを``define_table``に置くだけで十分です。例えば次のようになります。
``
db.define_table('person', Field('name'))
db.define_table('doctor', db.person, Field('specialization'))
``:code

``dummy table``:inxx
データベースに格納されないダミーテーブルを定義して、他の複数の場所で再利用することも可能です。例:

``
signature = db.Table(db, 'signature',
    Field('created_on', 'datetime', default=request.now),
    Field('created_by', db.auth_user, default=auth.user_id),
    Field('updated_on', 'datetime', update=request.now),
    Field('updated_by', db.auth_user, update=auth.user_id))

db.define_table('payment', Field('amount', 'double'), signature)
``:code

この例は、標準のweb2py認証が有効になっていることを前提としています。

もし``Auth``を利用している場合は、このようなテーブルをweb2pyが既に作成済みです。

``
auth = Auth(db)
db.define_table('payment', Field('amount', 'double'), auth.signature)
``
テーブル継承を使用する際に、バリデータも継承したい場合は、継承テーブルを定義する前に継承元のバリデータを定義しておく必要があります。

#### コモンフィールドとマルチテナント
``common fields``:inxx
``multi tenancy``:inxx

``db._common_fields``は全てのテーブルに属するフィールドのリストです。このリストにテーブルを含むこともでき、その場合は該当テーブルの全てのフィールドがリストされたとして理解します。例えば、``auth``を除く全てのテーブルにsignatureを追加したい場合があります。この場合、``db.define_tables()``の後で、且つ、それ以外のテーブルを定義する前に、以下を挿入します。

``
db._common_fields.append(auth.signature)
``

"request_tenant"は特別なフィールドです。このフィールドは（標準での定義が）存在しませんが、自分で作成して、いくつか（または全てのテーブル）のテーブルに追加できます。

``
db._common_fields.append(Field('request_tenant',
    default=request.env.http_host,writable=False))
``

``db.request_tenant``というフィールドを持っているテーブルは、全てのクエリの全てのレコードが、常に自動でフィルタされます。

``
db.table.request_tenant == db.table.request_tenant.default
``:code

そしてレコードの挿入のたびに、デフォルトの値がセットされます。上記の例では以下がセットされます。
``
default = request.env.http_host
``
つまり、アプリ上の全てのテーブルとクエリを以下でフィルタするという選択をしたことになります。
``
db.table.request_tenant == request.env.http_host
``

この簡単なトリックで、アプリケーションを複数のテナントに対応したアプリケーションにすることができます。つまりアプリを、単一インスタンス上の単一データベースで運用しているおり、複数ドメイン（上記の例の場合、ドメイン名は``request.env.http_host``から取得）でのアクセスがアプリに対してある場合、訪問者が接続したドメイン名によって参照するデータが異なることになります。複数のオンラインストアを、単一アプリとデータベースを使用し異なるドメイン下で運用する場合などを、想像してみてください。

複数のテナントによるフィルタを``ignore_common_filters``:inxxで無効にできます。
``
rows = db(query, ignore_common_filters=True).select()
``:code

#### コモンフィルタ

コモンフィルタは上記の複数のテナントという考え方を一般化したものです。同じクエリを繰り返し使用させない簡単な方法を提供します。次のテーブル例を考えてください。

``
db.define_table('blog_post',
    Field('subject'),
    Field('post_text', 'text'),
    Field('is_public', 'boolean'),
    common_filter = lambda query: db.blog_post.is_public==True
)
``

このテーブルに対する選択、削除、更新は公開されたブログ記事だけを含みます。その属性はコントローラで変更できます。

``
db.blog_post._common_filter = lambda query: db.blog_post.is_public == True
``

それぞれのブログ記事検索に"db.blog_post.is_public==True"という条件を繰り返し使用する必要がなくなり、非公開ブログ記事の参照不可の設定忘れ、といったセキュリティ面も向上もできます。

もし意図的にコモンフィルタを外したい（例、管理者は非公開のブログ記事を参照できる）場合は、フィルタを削除することができます。
``
db.blog_post._common_filter = None
``
もしくは、無視するするには次のようにします。
``
db(query, ignore_common_filters=True).select(...)
``

#### カスタム``Field``型 (実験的)

``SQLCustomType``:inxx

新しい/カスタムフィールド型を定義することが可能です。圧縮されたバイナリデータを含むフィールドの例です。

``
from gluon.dal import SQLCustomType
import zlib

compressed = SQLCustomType(
     type ='text',
     native='text',
     encoder =(lambda x: zlib.compress(x or '')),
     decoder = (lambda x: zlib.decompress(x))
)

db.define_table('example', Field('data',type=compressed))
``:code

``SQLCustomType``はフィールド型のファクトリです。その``type``引数はweb2pyの標準型の一つでなければなりません。web2pyレベルで、そのフィールド値をどのように扱うべきか指示します。``native``はデータベースが接続されているかぎり使用できるフィールドの名前です。データベースエンジン特有の型名も許可します。``encoder``はデータ格納時に適用されるオプションの変換関数で、``decoder``は逆変換の関数です。

この機能は実験的とされています。現実的に長い間使用されて動作していますが、コードがポータブルでなくなります。例として、データベース特有のフィールド型を使用した場合にGoogle App Engine NoSQLで動作しなくなります。

#### テーブル定義なしでDALを使用

DALは以下のようにすることで、どのようなPythonプログラムからでも使用できます。

``
from gluon import DAL, Field
db = DAL('sqlite://storage.sqlite',folder='path/to/app/databases')
``:code

つまり、DALとFieldをインポートし、接続、.tableファイル（app/databasesフォルダ）を含むフォルダを指定すればよいです。

データやその属性にアクセスするには、``db.define_tables(...)``で接続する全てのテーブルを定義する必要があります。

もしデータにだけアクセスし、web2pyテーブル属性は必要がない場合は、.tableファイルにあるメタデータから必要な情報を読み込むようにweb2pyに指示するだけです。テーブルを再定義する必要はないです。

``
from gluon import DAL, Field
db = DAL('sqlite://storage.sqlite',folder='path/to/app/databases',
         auto_import=True))
``:code

これによって再定義せずに``db.table``に接続できます。

#### 異なるdbからデータをコピー

以下のデータベースを使用している場合を考えてください。

``
db = DAL('sqlite://storage.sqlite')
``

そして異なる接続文字で、別のデータベースに移動したいとします：

``
db = DAL('postgresql://username:password@hocalhost/mydb')
``

切り替える前に、新しいデータベースへデータを移動してメタデータを再構築したいです。新しいデータベースは存在するが空であると想定します。

web2pyはこれを実現するスクリプトを提供します：

``
cd web2py
python scripts/cpdb.py \
   -f applications/app/databases \
   -y 'sqlite://storage.sqlite' \
   -Y 'postgresql://username:password@hocalhost/mydb'
``

スクリプト実行後、単にモデルの接続文字を切り替えるだけで、全て動きます。新しいデータも存在しています。

このスクリプトはひとつのアプリケーションから別のアプリケーションへデータを移動できる様々なコマンドラインオプションを提供し、全てのテーブルを移動したり、一部だけ移動したり、テーブルのデータをクリアしたりします。詳しくは次を実行してみてください。

``
python scripts/cpdb.py -h
``

#### 新しいDALとアダプタの注意点

データベース抽象化レイヤのソースコードは2010年に全て書き換えられました。後方互換性を保ちながら、よりモジュール化し拡張性しやすくすることができました。ここで主要なロジックについて説明します。

"gluon/dal.py"ファイルはとりわけ次のクラスを定義します。

``
ConnectionPool
BaseAdapter extends ConnectionPool
Row
DAL
Reference
Table
Expression
Field
Query
Set
Rows
``

``BaseAdapter``を除き、使用方法については前節で説明しました。``Table``や``Set``オブジェクトがデータベースと通信する必要がある場合、アダプタにSQLを生成したり、関数を呼び出すメッソドを委譲します。

例：
For example:

``
db.myable.insert(myfield='myvalue')
``

以下を呼び出します
calls

``
Table.insert(myfield='myvalue')
``

これは以下を返すことでアダプタに委譲します：

``
db._adapter.insert(db.mytable,db.mytable._listify(dict(myfield='myvalue')))
``

ここで``db.mytable._listify``は引数の辞書を``(field,value)``のリストに変換し、``adapter``の``insert``メソッドを呼びます。``db._adapter``は大体次のようなことをしています。

``
query = db._adapter._insert(db.mytable,list_of_fields)
db._adapter.execute(query)
``

最初の行はクエリを作り、２行目で実行しています。

``BaseAdapter``は全てのアダプタのインターフェースを定義します。

執筆時点で、"gluon/dal.py"は次のアダプタを含みます。

``
SQLiteAdapter extends BaseAdapter
JDBCSQLiteAdapter extends SQLiteAdapter
MySQLAdapter extends BaseAdapter
PostgreSQLAdapter extends BaseAdapter
JDBCPostgreSQLAdapter extends PostgreSQLAdapter
OracleAdapter extends BaseAdapter
MSSQLAdapter extends BaseAdapter
MSSQL2Adapter extends MSSQLAdapter
FireBirdAdapter extends BaseAdapter
FireBirdEmbeddedAdapter extends FireBirdAdapter
InformixAdapter extends BaseAdapter
DB2Adapter extends BaseAdapter
IngresAdapter extends BaseAdapter
IngresUnicodeAdapter extends IngresAdapter
GoogleSQLAdapter extends MySQLAdapter
NoSQLAdapter extends BaseAdapter
GoogleDatastoreAdapter extends NoSQLAdapter
CubridAdapter extends MySQLAdapter (experimental)
TeradataAdapter extends DB2Adapter (experimental)
SAPDBAdapter extends BaseAdapter (experimental)
CouchDBAdapter extends NoSQLAdapter (experimental)
MongoDBAdapter extends NoSQLAdapter (experimental)
``

これは``BaseAdapter``をオーバーライドします。

それぞれのアダプタは、おおよそ次のような構造です。

``
class MySQLAdapter(BaseAdapter):

    # specify a diver to use
    driver = globals().get('pymysql',None)

    # map web2py types into database types
    types = {
        'boolean': 'CHAR(1)',
        'string': 'VARCHAR(%(length)s)',
        'text': 'LONGTEXT',
	...
        }

    # connect to the database using driver
    def __init__(self,db,uri,pool_size=0,folder=None,db_codec ='UTF-8',
                credential_decoder=lambda x:x, driver_args={},
                adapter_args={}):
        # parse uri string and store parameters in driver_args
        ...
        # define a connection function
        def connect(driver_args=driver_args):
            return self.driver.connect(**driver_args)
        # place it in the pool
        self.pool_connection(connect)
        # set optional parameters (after connection)
        self.execute('SET FOREIGN_KEY_CHECKS=1;')
        self.execute("SET sql_mode='NO_BACKSLASH_ESCAPES';")

   # override BaseAdapter methods as needed
   def lastrowid(self,table):
        self.execute('select last_insert_id();')
        return int(self.cursor.fetchone()[0])

``:code

様々なアダプタの例を参考にすれば、新しいアダプタを記述するのも簡単です。

``db``インスタンスが作られると：

``
db = DAL('mysql://...')
``

uri文字列の接頭辞はアダプタを定義しています。マッピングは"gluon/dal.py"で、次のように辞書型で定義されています。

``
ADAPTERS = {
    'sqlite': SQLiteAdapter,
    'sqlite:memory': SQLiteAdapter,
    'mysql': MySQLAdapter,
    'postgres': PostgreSQLAdapter,
    'oracle': OracleAdapter,
    'mssql': MSSQLAdapter,
    'mssql2': MSSQL2Adapter,
    'db2': DB2Adapter,
    'teradata': TeradataAdapter,
    'informix': InformixAdapter,
    'firebird': FireBirdAdapter,
    'firebird_embedded': FireBirdAdapter,
    'ingres': IngresAdapter,
    'ingresu': IngresUnicodeAdapter,
    'sapdb': SAPDBAdapter,
    'cubrid': CubridAdapter,
    'jdbc:sqlite': JDBCSQLiteAdapter,
    'jdbc:sqlite:memory': JDBCSQLiteAdapter,
    'jdbc:postgres': JDBCPostgreSQLAdapter,
    'gae': GoogleDatastoreAdapter, # discouraged, for backward compatibility
    'google:datastore': GoogleDatastoreAdapter,
    'google:sql': GoogleSQLAdapter,
    'couchdb': CouchDBAdapter,
    'mongodb': MongoDBAdapter,
}
``:code

uri文字列はアダプタ自身で、より詳細に解析されます。

どのようなアダプタでも異なるドライバに置き換えることができます：

``
from gluon.dal import MySQLAdapter
MySQLAdapter.driver = mysqldb
``
オプションのドライバ引数やアダプタ引数を指定することもできます。

``
db =DAL(..., driver_args={}, adapter_args={})
``

##### 第3版 - 翻訳: 細田謙二　レビュー: Omi Chiba
##### 第4版 - 翻訳: Omi Chiba　レビュー: Hitoshi Kato